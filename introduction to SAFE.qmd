---
title: "Introduction to SAFE"
subtitle: "A step by step online tutorial"
date: "`r Sys.Date()`"
author:
  - name: Shinichi Nakagawa
  - name: Ayumi Mizuno
  - name: Santiago Ortega
  - name: Daniel Noble
  - name: Alistair Senior
  - name: Erick J Lundgren
  - name: many others order TBD
format: 
  html:
    toc: true
    toc-location: left
    toc-depth: 6
    toc-float: true
    toc-expand: true
    toc-title: "**CONTENTS**"
    output-file: "index.html"
    # embed-resources: true
    # code-fold: true
    code-link: true
    code-tools: true
    # number-sections: false
    # bibliography: ./bib/ref.bib
    fontsize: "10"
    mainfont: "Helvetica"
    monofont: "Fira Code"
    # fontcolor: ""
    page-layout: article
    code-overflow: wrap
    df_print: paged
    theme: cosmo
    code-line-numbers: false
    grid:
      margin-width: 120px
# crossref: 
#   fig-title: Figure     # (default is "Figure")
#   tbl-title: Table     # (default is "Table")
#   title-delim: "â€”"     # (default is ":")
#   fig-prefix: Fig.     # (default is "Figure")
#   tbl-prefix: Table.   # (default is "Table")
editor_options: 
  chunk_output_type: console
execute:
  warning: false
  message: false
  tidy: true
---

## Introduction

If you have any questions, errors or bug reports, please feel free to contact Erick Lundgren (erick.lundgren\@gmail.com).

To run the code interactively (instead of just reading this lovely tutorial), do the following:

1.  Clone the github repo: https://github.com/ejlundgren/SAFE.git
2.  Run the code chunks in the SAFE simulations tutorial.qmd while in the R project session or just follow along here on the web

**QUESTION: I prefer data.table() and I wrote everything in that function...I can convert to dplyr no problem though if people are that picky. Does anyone care?**

## Load libraries

The `groundhog` package ensures that the library versions you use are the same as ours. You will need R version 4.5.0. Be sure to install `groundhog` if it is not already installed with `install.packages()`.

```{r, load_libraries}
#| label: load_libraries
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

# First, clean the environment:
rm(list = ls())

# Now load packages:
# install.packages("groundhog")
library("groundhog")
groundhog.library(pkg = c("data.table", "MASS", "crayon", 
                          "tmvtnorm", "here",
                          "parallel", "foreach", "doSNOW",
                          "ggplot2", "patchwork", "scico"),
                  date = "2025-04-15")

```

# An introduction to SAFE bootstrapping

SAFE bootstrapping is an incredible, seemingly magical, technique to calculate bias-corrected point estimates and sampling variance for effect sizes. SAFE bootstrapping is particularly useful for novel effect sizes for which sampling variance formulas may not be known. In some cases, it is also more unbiased than traditional plugin formulas for variance and point estimates.

## How does it work?

With SAFE bootstrapping, one draws a cloud of *hyperparameters* of all variables used in an effect size formula. You then apply your effect size formula to this cloud. The variance of this transformed cloud is the sampling variance of your effect size! 

You can then calculate a bias-transformed point estimate by taking the mean of this transformed cloud and subtracting it from 2 times the point estimate derived from the original variables.

Let's demonstrate.

Imagine you're conducting a meta-analysis of animal responses to an environmental stressor. Many studies are reporting data as mean 'latency time' (e.g., time until an animal runs). However, you want to create an effect size of 'speed' from latency time. This is simple: take the inverse of latency (`1/latency`). Here let's start with three mean latency times and convert to our new 'speed' effect size

```{r, speed_example}
#| label: speed_example
# The type of data summaries you might extract for a meta-analysis:
mean_latency <- c(15, 30, 21)
           n <- c(25, 31, 50)
          sd <- c(4.6, 3.1, 2.5)

# New effect size:
1/mean_latency

```
The effect size is trivial to calculate. But what is the sampling variance of this effect size, given that each of these measurements was associated with measurement sample size and standard deviation?

You could use calculus to derive a first-order sampling variance formula. Or you could use SAFE bootstrapping. 

### Step 1: Draw hyperparameters.
If the word 'hyperparameter' is scary, what we mean is a distribution associated with the variables in our effect size formula, in this case mean `latency`. 

This is different than drawing from a population based on mean and standard deviation, which will have a broad distribution, reflecting the underlying population. Instead, we're interested in drawing a distribution of the **means**â€”the hyperparameter of our effect size of interest. To do this, we draw from a normal distribution with **standard error** to describe dispersion.

To convert our 'latency' time to our 'speed' effect size with SAFE, let's draw 10,000 samples of the mean latency hyperparameter from a normal distribution, with standard error as our `sd`. To avoid using `lapply` or loops, we'll just do this on a single latency time and associated standard deviation and sample size. 

**Shinichi, I don't fully understand why we square root the N for this effect size but not the others** DN COMMENT: Erick, we sqrt N because we need the sampling error of the mean, which is se = sd/sqrt(N). Depending on the effect size you use, the sampling error for those will be a bit different. For example, with logRoM, the sampling error is sqrt((sd1^2/(n1*x1^2)) + (sd2^2/(n2*x2^2))). You will notice that for this you have two groups and you are 1) log transforming the means and 2) using sd and n for both groups. So the sampling error is a bit more complex because you need to account for the scale change when log transforming the means and you also now have two groups each with their own sampling variance. So, the total sampling variance is simply their sum.

```{r, speed_cloud}
#| label: speed_cloud

# Define the variables
 x <- 15  # The mean latency time
sd <- 4.6 # standard deviation of latency time
 n <- 25  # sample size, e.g., number of animals in the experiment

# Simulate a cloud of hyperparameters
cloud <- rnorm(1e6,                  # number of samples
               mean = x,             # mean latency time
                 sd = sd / sqrt(n))  # standard error

# Have a look a the cloud (distribution)
head(cloud)
hist(cloud)

```

### Step 2: Transform hyperparameters to target effect size
Now, let's transform this cloud of hyperparameters to 'speed' with our 'plugin' or definition formula `1/x`. These values are centered on our original effect size, which we'll overlay in red

```{r, speed_transform}
#| label: speed_transform
# Transform the cloud to our effect size we want
       cloud_trans <- 1/cloud

# Our plugin effect size
                 x <- 15
plugin_effect_size <- 1/x
plugin_effect_size

# Our plugin effect size
hist(cloud_trans, main = "Transformed hyperparameter cloud")
abline(v = plugin_effect_size, col = "red")

```

### Step 3: Calculate sampling variance

To calculate sampling variance, we'll simply calculate the variance of this transformed cloud.

```{r}
safe_vi <- var(cloud_trans)

safe_vi
```

Voila! Sampling variance for a novel effect size. 

### Step 4: Calculate bias-corrected effect size

However, given low sample sizes for some measurements, and the knowledge that point estimates can be biased at low N, let's also calculate a bias-corrected point estimate from this cloud of hyperparameters:

**It'd be nice to explain the logic here better...without formulas haha**

```{r}

safe_yi <- (2 * plugin_effect_size) - mean(cloud_trans)

safe_yi

```

Let's compare this to the original point estimate:

```{r}

safe_yi
plugin_effect_size

```
So similar! And potentially less biased. Let's find out. Below, we'll use Monte Carlo simulations to compare the bias of estimates from SAFE to estimates from just plugging into a formula. But first, let's introduce a helpful function for calculating SAFE for a variety of effect sizes.

## Load encapsulated functions

We wrote a function to calculate effect sizes both with plugin estimators and with SAFE. This function can be sourced into the local environment. Let's load the function and then calculate effect sizes, with SAFE, for several examples from the main text. The function is located in the github repo at scripts/SAFE_function.R. This function returns a data.table (basically a *fast* data.frame) with columns for plugin effect sizes and sampling variances (denoted with `_first` or `_second` based on derivative order) and SAFE effect sizes and sampling variances (denoted with `_safe`). Point estimates (effect sizes) are denoted with `yi_` while sampling variances are denoted with `vi_`.

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

source("scripts/SAFE_function.R")

# For a single effect size and sampling variance:
eff_size(x1 = 14.5, x2 = 7.9, 
         sd1 = 1.3, sd2 = 2,
         n1 = 20, n2 = 20, 
         effect_type = "lnRoM",
         SAFE = TRUE,
         verbose = TRUE,
         SAFE_boots = 1e6)

```

The function also works with a vector of raw data:

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

eff_size(x1 = c(14.5, 13, 15.8), 
         x2 = c(7.9, 21, 18.4), 
         sd1 = c(1.3, 2, 1.9), 
         sd2 = c(2, 3.1, 1.4),
         n1 = c(20, 20, 20), 
         n2 = c(20, 15, 18), 
         effect_type = "SMD",
         SAFE = TRUE,
         verbose = FALSE,
         parallelize = TRUE,
         SAFE_boots = 1e6)

```

For a full list of options that eff_size can calculate, run:

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

eff_size()

```

# How good is SAFE?

We simulated the bias of SAFE calculations versus normal plugin calculations for a variety of common, and less common, effect sizes. We did this across a range of input variables, particularly sample size and the number of SAFE bootstraps. The creation of these scenarios differed for each effect size (based on input variables). The scenarios can be loaded as follows. Let's look at the simulations for lnRoM:

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

scenarios <- readRDS("builds/scenarios.Rds")

# Subset scenarios:
guide <- scenarios[effect_type == "lnRoM" &
                     boots == 1e6, ]

guide[, .(effect_type, scenario_id, boots,
                   true_mean1, true_mean2, 
                   true_sd1, true_sd2,
                   sample_size1, sample_size2)]

```

To evaluate effect size performance, we conducted Monte Carlo simulations for each scenario. In these simulations, we created simulated datasets based on true values for each scenario. We then calculated effect sizes and sampling variances (both with plugin formulas and SAFE) for the 'true' values and based on the simulated dataset. We did this 1e5 times for each scenario.

In these Monte Carlo simulation, we were interested in bias, or the difference between the 'true' estimands (i.e., sampling variance and effect sizes) and the estimates (of sampling variance and effect sizes) produced from various methods and applied to the simulated data. We'll explain the difference between estimands, estimators, and estimates below.

To illustrate, we'll do a dummy simulation for lnRoM. Note that the means/sd for each scenario are the same. The only variables that differ are sample sizes. To make this tractable, we'll only run 100 simulations.

To speed things up we will do this in parallel. The function `prepare_cluster()` below can help set things up, including a progress bar so you don't lose your mind wondering what's going on in there.

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

set.seed(2025)

# Prepare cluster:
prepare_cluster <- function(n){
    require("parallel")
    require("foreach")
    require("doSNOW")
    
    nCores <- parallel::detectCores() -1 
    cl <- makeCluster(nCores)
    registerDoSNOW(cl)
    
    # Progress bar
    pb <- txtProgressBar(max = n, style = 3)
    progress <- function(n) setTxtProgressBar(pb, n)
    opts <- list(progress = progress)
    ret <- list(opts, pb, cl)
    names(ret) <- c("options", "progress", "cluster")
    
    return(ret)
    
    cat("Pass 'x$options' to .opts in foreach;
      'x$progress' to setTxtProgressBar(x$progress, i);
      'x$cluster' to stopCluster(x$cluster) after foreach")
  }

```

Now we will run 100 simulations to showcase how this method works. The actual simulations had a length of 1e5 and are loaded and visualized below. The first part of this code (inside the `lapply`) creates simulated data based on 'true' means and standard deviations. This data is then summarized to a simulation mean and standard deviation. We will then calculate effect sizes and sampling variances for the 'true' values and simulated values. Note that even with only 100 iterations, this can take a minute, so feel free to load the already run dummy dataset in the next code block.

```{r}
#| eval: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

rerun <- F
if(rerun){
  
  monte_carlo_N <- 100
  
  clust_out <- prepare_cluster(n = monte_carlo_N)
  
  res <- foreach(i = 1:monte_carlo_N, 
         .options.snow = clust_out$options,
         .errorhandling = "pass",
         .packages = c("data.table", "MASS", "tmvtnorm")) %dopar% {
           
   # Calculate 'true' values from scenario:
   true_point <- eff_size(x1 = guide$true_mean1, x2 = guide$true_mean2,
                          sd1 = guide$true_sd1,  sd2 = guide$true_sd2,
                          n1 = guide$sample_size1, n2 = guide$sample_size2, 
                          effect_type = "lnRoM",
                          SAFE = FALSE,
                          verbose = FALSE,
                          SAFE_boots = 1e6)
   setnames(true_point,
            c("yi_first", "vi_first", 
              "yi_second", "vi_second"),
            c("true_y_plugin_1st", "true_v_plugin_1st",
              "true_y_plugin_2nd", "true_v_plugin_2nd"))
   
    # Simulate data for each scenario in an lapply: 
   sim_dat <- lapply(1:nrow(guide), function(x){
     
     # Simulate data for guide
     sig <- diag(c(guide$true_sd1[x]^2,
                   guide$true_sd2[x]^2))
     
     means <- c(m1 = guide$true_mean1[x],
                m2 = guide$true_mean2[x])
     
     y <- rtmvnorm(n = max(c(guide$sample_size1[x], guide$sample_size2[x])),
                     mean = means,
                     sigma = sig,
                     lower = rep(0, length(means)),
                     upper = rep(Inf, length(means)),
                     algorithm = "gibbs") |>
       as.data.frame() |>
       setDT()
     names(y) <- c("m1", "m2")
     
     # Filter to number of samples per treatment
     sim_dat <- list(x1 = y[1:guide$sample_size1[x], ]$m1,
                     x2 = y[1:guide$sample_size2[x], ]$m2)
     
     sim_dat <- data.table(sim_mean1 = mean(sim_dat$x1),
                           sim_mean2 = mean(sim_dat$x2),
                           sim_sd1 = sd(sim_dat$x1),
                           sim_sd2 = sd(sim_dat$x2),
                           sim_sample_size1 = length(sim_dat$x1),
                           sim_sample_size2 = length(sim_dat$x2))
     return(sim_dat)
   }) |> rbindlist()
   
  
   out <- eff_size(x1 = sim_dat$sim_mean1, x2 = sim_dat$sim_mean2,
                   sd1 = sim_dat$sim_sd1,  sd2 = sim_dat$sim_sd2,
                   n1 = guide$sample_size1, n2 = guide$sample_size2, 
                   effect_type = "lnRoM",
                   SAFE = TRUE,
                   verbose = FALSE,
                   parallelize = FALSE,
                   SAFE_boots = 1e6)
   setnames(out,
            c("yi_first", "vi_first", 
              "yi_second", "vi_second"),
            c("sim_y_plugin_1st", "sim_v_plugin_1st",
              "sim_y_plugin_2nd", "sim_v_plugin_2nd"))
   
   # Store results:
   results <- data.table(guide,
                         sim_dat,
                         true_point,
                         out)
   
   setTxtProgressBar(clust_out$progress, i)
   
   return(results)
  
  }
  stopCluster(clust_out$cluster)
  
  res <- rbindlist(res)  
  head(res)
}

```

Or just load the full simulation (1e5) here:

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

res <- readRDS("builds/lnRoM_simulation.Rds")

head(res, 3)

```

## Calculate bias

To interpret the simulation results, it is essential to understand the difference between *estimands*, *estimators*, and *estimates*.

**Estimands** are the 'true' value.

**Estimators** are the methods used to estimate the estimand. What a tongue twister! In our case, the estimators are the 1st order effect size (e.g., definition formula), the 2nd order effect size that has been adjusted (usually using the delta method, except for Hedges' g) to reduce bias, and the SAFE method.

**Estimates** are the estimates of the estimands produced by the estimators ðŸ¤ 

### Effect size (point estimate) bias

In the case of our effect sizes, there are two estimands that we're interested in estimating: the 'true' effect size (based on the definition formula of the effect size type) and sampling variance. To calculate the bias of our various estimators in estimating effect sizes, we calculate the mean of the estimates from each simulated dataset and subtract the estimand value (the true effect size off the 'true' values).

Here we will calculate bias in our estimates of effect sizes:

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

bias <- function(estimates, estimand){
  return(mean(estimates) - unique(estimand))
}

point.bias <- res[, .(plugin_1st = bias(sim_y_plugin_1st, true_y_plugin_1st),
                      plugin_2nd = bias(sim_y_plugin_2nd, true_y_plugin_1st),
                      safe = bias(yi_safe, true_y_plugin_1st)),
                  by = .(scenario_id, sample_size1, sample_size2)] |> unique()
head(point.bias)

# Melt this to make it plottable:
point.bias.long <- melt(point.bias,
                        id.vars = c("scenario_id", "sample_size1", "sample_size2"),
                        value.name = "bias",
                        variable.name = "estimator")

head(point.bias.long)

# Sort by sample size 
setorder(point.bias.long, sample_size1)

ggplot(data = point.bias.long[sample_size1 == sample_size2, ],
       aes(x = sample_size1, y = bias, color = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(linewidth = 1)+
  xlab("Sample size")+
  ylab("Bias")+
  coord_cartesian(ylim = c(-0.01, 0.01))+
  scale_color_manual("Estimator",
                       labels = c("plugin_1st" = "1st order plugin\n(definition formula)",
                                  "plugin_2nd" = "2nd order plugin\n(bias-corrected formula)",
                                  "safe" = "SAFE bootstrapping"),
                       values = c("plugin_1st" = "#A8DADC",
                                   "plugin_2nd" = "#1D3557",
                                   "safe" = "#E63946"))+
  theme_bw()+
  theme(panel.border = element_blank(),
        panel.grid = element_blank(),
        legend.position = "bottom")

```

This indicates that the least biased estimator is the first order definition formula (light blue). SAFE (red) and the 2nd order plugin (navy blue) perform similarly. These bias values are incredibly small, indicating that all options are fair, except for at low sample sizes, when the first-order definition formula is quite biased.

### Sampling variance bias

Interestingly, there is no way to know the 'true' estimand for sampling variance. **WHICH I DON'T FULLY UNDERSTAND**. To calculate bias for our sampling variance estimates, we actually calculate the variance in point estimates for each estimator and use *each* of these as the estimand. With 3 estimators, and thus 3 estimands, we'll thus end up with 9 calculations of bias.

Since we're interested in relative bias (**Not entirely sure why**), we'll calculate bias as above but divide by the estimand and multiply by 100.

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

# First, calculate variance in point estimates as our 'estimand'
res[, var_estimand_1st := var(sim_y_plugin_1st), 
    by = .(scenario_id)]
res[, var_estimand_2nd := var(sim_y_plugin_2nd), 
    by = .(scenario_id)]
res[, var_estimand_SAFE := var(yi_safe), 
    by = .(scenario_id)]

# To make this easier to read, we'll encapsulate the relative bias in a function:
relative_bias <- function(estimates,
                          estimand){
  return(((mean(estimates) - unique(estimand)) / estimand) * 100)
}

# Now summarize and calculate relative bias per scenario ID
var.bias <- res[, .(SAFE_estimate.1st_estimand = relative_bias(vi_safe, var_estimand_1st),
                    SAFE_estimate.2nd_estimand = relative_bias(vi_safe, var_estimand_2nd),
                    SAFE_estimate.SAFE_estimand = relative_bias(vi_safe, var_estimand_SAFE),
                    plugin_1st_estimate.1st_estimand = relative_bias(sim_v_plugin_1st, var_estimand_1st),
                    plugin_1st_estimate.2nd_estimand = relative_bias(sim_v_plugin_1st, var_estimand_2nd),
                    plugin_1st_estimate.SAFE_estimand = relative_bias(sim_v_plugin_1st, var_estimand_SAFE),
                    plugin_2nd_estimate.1st_estimand = relative_bias(sim_v_plugin_2nd, var_estimand_1st),
                    plugin_2nd_estimate.2nd_estimand = relative_bias(sim_v_plugin_2nd, var_estimand_2nd),
                    plugin_2nd_estimate.SAFE_estimand = relative_bias(sim_v_plugin_2nd, var_estimand_SAFE)),
    by = .(scenario_id, sample_size1, sample_size2)] |> unique()


# Now melt:
var.bias.long <- melt(var.bias,
                      id.vars = c("scenario_id", "sample_size1", "sample_size2"))
head(var.bias.long)

# Split the 'variable' into estimator and estimand for plotting
var.bias.long[, c("Estimator", "Estimand") := tstrsplit(variable, ".", fixed = TRUE)]

# Sort the dataset by sample size
setorder(var.bias.long, sample_size1)

# Plot
ggplot(data = var.bias.long[sample_size1 == sample_size2, ], 
       aes(x = sample_size1, y = value, color = Estimator))+
    geom_path(linewidth = 1)+
  geom_hline(yintercept = 0)+
  xlab("Sample size")+
  ylab("Relative bias (%)")+
  scale_color_manual("Estimator",
                     labels = c("plugin_1st_estimate" = "1st order plugin\n(definition formula)",
                                  "plugin_2nd_estimate" = "2nd order plugin\n(bias-corrected formula)",
                                  "SAFE_estimate" = "SAFE bootstrapping"),
                     values = c("plugin_1st_estimate" = "#A8DADC",
                               "plugin_2nd_estimate" = "#1D3557",
                               "SAFE_estimate" = "#E63946"))+
  facet_wrap(~Estimand,
             ncol = 1,
             labeller = as_labeller(c("1st_estimand" = "1st order plugin estimand\n(definition formula)",
                                    "2nd_estimand" = "2nd order plugin estimand",
                                    "SAFE_estimand" = "SAFE estimand")))+
  theme_bw()+
  theme(panel.border = element_blank(),
        panel.grid = element_blank(),
        strip.background = element_blank(),
        legend.position = "bottom")

```

We see here that SAFE (red) is slightly more biased, but in a conservative direction, than the other estimators.

## Plot all simulations results

Now let's look at the rest of the simulation results.

```{r}
#| echo: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sim_results <- readRDS("builds/all_scenarios_summarized.Rds")
sim_results <- sim_results[boots == 1e5, ]

```

# **These are plotting 1e5 right now...Rerunning 1e6. Will update soon**
### Speed

This was our dummy effect size in the beginning. How do the point and variance estimates calculated by SAFE compare to just calculating 1 / x for point estimates? 

We compared the variance estimates from SAFE to variance estimates produced by a 1st-order derivative sampling variance formula derived with the delta method (denoted as 1st order plugin here). Let's see which did better!

```{r}
#| echo: false
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

var_lab <- "Relative bias of\nvariance estimates (%)"
point_lab <- "Bias of point\nestimates"

theme_SAFE <- theme_bw()+
  theme(panel.border = element_blank(),
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5),
        panel.grid = element_blank(),
        strip.background = element_blank())

labs = c("plugin_1st" = "1st order plugin",
           "plugin_2nd" = "2nd order plugin",
           "safe" = "SAFE")

pal = c("plugin_1st" = "#A8DADC",
           "plugin_2nd" = "#1D3557",
           "safe" = "#E63946")
pt_size <- 2

facet_labs <- as_labeller(c("plugin_1st" = "1st order estimand",
                            "plugin_2nd" = "2nd order plugin estimand",
                            "safe" = "SAFE estimand"))
```


```{r}
#| echo: false
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"
sub_dat <- sim_results[effect_type == "reciprocal", ]

setorder(sub_dat, sample_size)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias"), ], 
            aes(x = sample_size, y = value, color = estimator,
                group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             labeller = facet_labs)+
  coord_cartesian(ylim = c(-0.0005, 0.0005))+
  ggtitle("Speed (1 / x)")+
  theme_SAFE+
  theme(legend.position = "none") 

p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias"), ], 
             aes(x = sample_size, y = value, color = estimator,
                 group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             labeller = facet_labs,
             nrow = 2)+
  coord_cartesian(ylim = c(-5, 5))+
  theme_SAFE+
  theme(legend.position = "bottom")

p.point + p.variance + plot_layout(ncol = 1, heights = c(1/3, 2/3))

```

### SMD 4-multivariate normal

The SAFE estimator for this effect size was calculated with 4 multivariate normal distributions for both mean and SD, as both of these parameters are in the definition formula (Cohen's d) of SMD. Let's compare the bias of SAFE, Cohen's d, and Hedges' g.


```{r}
#| echo: false
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "SMD_normal", ]

setorder(sub_dat, sample_size1)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias") & sample_size_ratio == 1, ], 
                  aes(x = sample_size1, y = value, color = estimator,
                      group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             labeller = as_labeller(c("plugin_1st" = "Cohen's d estimand")))+
  coord_cartesian(ylim = c(-0.1, 0.1))+
  ggtitle("SMD")+
  theme_SAFE+
  theme(legend.position = "none") 

#
p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias") & sample_size_ratio == 1, ], 
                     aes(x = sample_size1, y = value, color = estimator,
                         group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = c(plugin_1st = "Cohen's d", 
                                plugin_2nd = "Hedges' g", 
                                safe = "SAFE"))+
  coord_cartesian(ylim = c(-30, 30))+
  facet_wrap(~estimand, 
             ncol = 1,
             labeller = as_labeller(c("plugin_1st" = "Cohen's d estimand",
                                      "plugin_2nd" = "Hedges' g estimand",
                                      "safe" = "SAFE estimand")))+
  theme_SAFE+
  theme(legend.position = "bottom")

p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```

### SMD 2-multivariate normal and 2-Wishart

With this estimator, the SAFE calculation used the normal distribution to simulate the two means but the Wishart distribution to estimate the SD. 

**This is finishing up on the cluster**
```{r}
#| echo: false
#| eval: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "SMD_Wishart", ]
setorder(sub_dat, sample_size1)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias") & sample_size_ratio == 1, ],
                  aes(x = sample_size1, y = value, color = estimator,
                      group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
geom_point(size = pt_size)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator",
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand,
             labeller = facet_labs)+
  coord_cartesian(ylim = c(-0.1, 0.1))+
  ggtitle("SMD (x1 - x2) / pooled SD",
          subtitle = "with n1==n2")+
  theme_SAFE+
  theme(legend.position = "none")

#
p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias") & sample_size_ratio == 1, ],
                     aes(x = sample_size1, y = value, color = estimator,
                         group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
geom_point(size = pt_size)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator",
                     values = pal,
                     labels = c(plugin_1st = "Cohen's d",
                                plugin_2nd = "Hedges' g",
                                safe = "SAFE"))+
  facet_wrap(~estimand,
             ncol = 1,
             labeller = as_labeller(c("plugin_1st_mc" = "Monte Carlo Cohen's d estimand",
                                      "plugin_2nd_mc" = "Monte Carlo Hedges' g estimand",
                                      "safe_mc" = "Monte Carlo SAFE variance estimand",
                                      "true_1st" = "True Cohen's d point estimand",
                                      "true_2nd" = "True Hedges' g point estimand")))+
  coord_cartesian(ylim = c(-60, 60))+
  theme_SAFE+
  theme(legend.position = "bottom")

p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```

### lnCVR 4-multivariate normal

The SAFE estimator for this effect size was calculated with 4 multivariate normal distributions for both mean and SD.

**Finishing up on cluster**

```{r}
#| echo: false
#| eval: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnCVR_normal", ]
setorder(sub_dat, sample_size1)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias") & 
                                   sample_size_ratio == 1, ], 
                  aes(x = sample_size1, y = value, color = estimator,
                      group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             labeller = facet_labs)+
  coord_cartesian(ylim = c(-0.05, 0.05))+
  ggtitle("lnCVR")+
  theme_SAFE+
  theme(legend.position = "none") 

#
p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias") & sample_size_ratio == 1, ], 
                     aes(x = sample_size1, y = value, color = estimator,
                         group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             ncol = 1,
             labeller = facet_labs)+
  coord_cartesian(ylim = c(-60, 60))+
  theme_SAFE+
  theme(legend.position = "bottom")

p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```

### lnCVR 2-multivariate normal and 2-Wishart

The SAFE estimator for this effect size was calculated with 2-multivariate normal distribution for the means and 2-Wishart distributions for the SD.

**This is finishing up on the cluster**

```{r}
#| echo: false
#| eval: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnCVR_Wishart", ]
setorder(sub_dat, sample_size1)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias") &
                                   sample_size_ratio == 1, ],
                  aes(x = sample_size1, y = value, color = estimator,
                      group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
geom_point(size = pt_size)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator",
                     values = pal,
                     labels = labs)+
  coord_cartesian(ylim = c(-0.05, 0.05))+
  facet_wrap(~estimand,
             labeller = facet_labs)+
  ggtitle("lnCVR",
          subtitle = "with n1==n2")+
  theme_SAFE+
  theme(legend.position = "none") #, legend.position.inside = c(.85, .85)

#
p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias") & sample_size_ratio == 1, ],
                     aes(x = sample_size1, y = value, color = estimator,
                         group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
geom_point(size = pt_size)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator",
                     values = pal,
                     labels = labs)+
  coord_cartesian(ylim = c(-30, 30))+
  facet_wrap(~estimand,
             ncol = 1,
             labeller = facet_labs)+
  theme_SAFE+
  theme(legend.position = "bottom")

p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```

### lnOR

In this effect size estimation, the SAFE calculation used a binomial distribution to draw random binomial samples for 'a' and 'c'.

```{r}
#| echo: false
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnOR", ]
setorder(sub_dat, n1)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias"), ], 
                  aes(x = n1, y = value, color = estimator,
                      group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand,
             labeller = facet_labs)+
  coord_cartesian(ylim = c(-.25, .25))+
  ggtitle("lnOR")+
  theme_SAFE+
  theme(legend.position = "none") 

#
p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias"), ], 
                     aes(x = n1, y = value, color = estimator,
                         group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             ncol = 1,
             labeller = facet_labs)+
  coord_cartesian(ylim = c(-90, 90))+
  theme_SAFE+
  theme(legend.position = "bottom")

p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```

### lnRR

In this effect size estimation, the SAFE calculation drew 'a' and 'c' from a binomial distribution.

```{r}
#| echo: false
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnRR", ]
setorder(sub_dat, n1)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias") , ], 
                  aes(x = n1, y = value, color = estimator,
                      group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             labeller = facet_labs)+
  coord_cartesian(ylim = c(-.2, .2))+
  ggtitle("lnRR")+
  theme_SAFE+
  theme(legend.position = "none") 

#
p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias"), ], 
                     aes(x = n1, y = value, color = estimator,
                         group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             ncol = 1,
             labeller = facet_labs)+
  coord_cartesian(ylim = c(-30, 30))+
  theme_SAFE+
  theme(legend.position = "bottom")

p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```

### Hardy Weinberg Disequilibrium

In this effect size estimation, the SAFE calculation drew 'n_AA', 'n_Aa', and 'n_aa' from a binomial distribution.

```{r}
#| echo: false
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnHWE_A", ]
setorder(sub_dat, n)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias"), ], 
                  aes(x = n, y = value, color = estimator,
                      group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             labeller = facet_labs)+
  coord_cartesian(ylim = c(-0.1, 0.1))+
  ggtitle("Hardy-Weinburg Disequilibrium")+
  theme_SAFE+
  theme(legend.position = "none") 

#
p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias") & 
                                   p_AA == 0.25 & p_aa == 0.25 & p_Aa == 0.5, ], 
                     aes(x = n, y = value, color = estimator,
                         group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             ncol = 1,
             labeller = facet_labs)+
    coord_cartesian(ylim = c(-15, 15))+
  theme_SAFE+
  theme(legend.position = "bottom")


p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```

# How many SAFE bootstraps?
The SAFE method relies on bootstrapping to calculate effect size point estimates and sampling variance. It's sort of magical how well it works! But, how many bootstraps are necessary? Let's find out by doing another Monte Carlo simulation, again of lnRoM. This time, instead of calculating bias, we'll look at the standard deviation of the point and sampling variance estimates as we change the number of bootstraps.

Let's choose two bootstrap lengths: 100 and 1,000. We'll run a simulation 1,000 times just to make this easy. (See below for full 1e5 simulation results)

```{r}
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

  # Create some scenarios based on combinations of sample size and boot-length
  scenario <- CJ(true_mean1 = 13.4, true_sd1 = 4.6,
                 true_mean2 = 16.1, true_sd2 = 3.9,
                 sample_size1 = c(5, 10, 150))
  scenario[, sample_size2 := sample_size1]
  scenario

```

Now let's run this in a foreach loop. If you'd rather not run this on your machine, if `run` == FALSE, the code will just load the already finished simulation. Note that in this simulation, we're evaluating SAFE estimates using only the 'true' values. In the full 1e5 simulations below, we'll evalaute SAFE on simulated data.

**@Shinichi, @Alistair, @Daniel: Is that ok? This simulation right here is only for illustration purposes. I can simulate data for it though if you all think I should. Since we're not interested in bias from 'true' it seems like it doesn't matter?**


```{r}
#| eval: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

out <- list()
sub_scenario <- c()
N <- 1000
res <- list()

clust_out <- prepare_cluster(n = N)

res <- foreach(i = 1:N, 
              .options.snow = clust_out$options,
             .errorhandling = "stop",
             .packages = c("data.table", "MASS",
                           "crayon", "tmvtnorm")) %dopar% {

 # Now calculate SAFE with 100 bootstraps                                         
 out[[1]] <- eff_size(x1 = scenario$true_mean1,
                 x2 = scenario$true_mean2,
                 sd1 = scenario$true_sd1,
                 sd2 = scenario$true_sd2,
                 n1 = scenario$sample_size1,
                 n2 = scenario$sample_size2,
                 effect_type = "lnRoM",
                 SAFE = TRUE,
                 verbose = FALSE,
                 parallelize = FALSE,
                 SAFE_boots = 100) 
 
  out[[1]] <- data.table(out[[1]],
                         sample_size = scenario$sample_size1,
                         boots = 100)
  out[[1]]
  
  # Now with 1000 bootstraps
  out[[2]] <- eff_size(x1 = scenario$true_mean1,
                 x2 = scenario$true_mean2,
                 sd1 = scenario$true_sd1,
                 sd2 = scenario$true_sd2,
                 n1 = scenario$sample_size1,
                 n2 = scenario$sample_size2,
                 effect_type = "lnRoM",
                 SAFE = TRUE,
                 verbose = FALSE,
                 parallelize = FALSE,
                 SAFE_boots = 1000) 
  
  out[[2]] <-  data.table(out[[2]],
                         sample_size = scenario$sample_size1,
                         boots = 1000)
  out[[2]]   
  
  return(rbindlist(out))
}

res.dt <- rbindlist(res)

saveRDS(res.dt, "builds/dummy_bootstrap_simulation.Rds")

```

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"
res.dt <- readRDS("builds/dummy_bootstrap_simulation.Rds")

```

Let's look at the dispersion of the SAFE estimates as a function of sample size and bootstrap length.

```{r}
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

head(res.dt)

# First, the point estimates:
ggplot(data = res.dt, 
       aes(x = as.factor(sample_size), y = yi_safe, 
           fill = boots,
           group = interaction(sample_size, boots)))+
  geom_jitter(alpha = .5, shape = 21,
              position = position_jitterdodge(dodge.width = 1))+
  geom_violin(position = position_dodge(width = 1))+
  ylab("SAFE Point Estimate")+
  xlab("Scenario sample size")+
  scale_fill_scico("Number of SAFE bootstraps",
                   palette = "hawaii")+
  theme_bw()+
  theme(panel.border = element_blank(),
        panel.grid = element_blank(),
        strip.background = element_blank(),
        legend.position = "bottom")

```

Now let's look at the variance estimates:

```{r}
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

ggplot(data = res.dt, 
       aes(x = as.factor(sample_size), y = vi_safe, 
           fill = boots,
           group = interaction(sample_size, boots)))+
  geom_jitter(alpha = .5, shape = 21,
              position = position_jitterdodge(dodge.width = 1))+
  geom_violin(position = position_dodge(width = 1))+
  ylab("SAFE Variance Estimate")+
  xlab("Scenario sample size")+
  scale_fill_scico("Number of SAFE bootstraps",
                   palette = "hawaii")+
  theme_bw()+
  theme(panel.border = element_blank(),
        panel.grid = element_blank(),
        strip.background = element_blank(),
        legend.position = "bottom")


```

Looks like the dispersion in estimates is shaped by number of SAFE bootstraps and improves considerably with 1,000 bootstraps, especially at low sample sizes. Another way to visualize this (which we'll use below in the proper 1e5 simulations) is to plot the standard deviation.

```{r}
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

res.summary <- res.dt[, .(sd_point_estimate = sd(yi_safe),
                       sd_variance_estimate = sd(vi_safe)),
                   by = .(sample_size, boots)]
res.summary

# Let's melt this to make a single plot:
res.summary.mlt <- melt(res.summary,
                        id.vars = c("sample_size", "boots"))
res.summary.mlt
setorder(res.summary.mlt, boots)

ggplot(data = res.summary.mlt,
       aes(x = boots, y = value, color = sample_size,
           group = interaction(sample_size)))+
  geom_path()+
  geom_point(size = pt_size)+
  facet_wrap(~variable,
             labeller = as_labeller(c("sd_point_estimate" = "Point estimate",
                                      "sd_variance_estimate" = "Variance estimate")))+
  scale_color_scico("Scenario sample size",
                   palette = "hawaii")+
  xlab("SAFE bootstrap length")+
  ylab("Standard deviation of estimate")+
  theme_bw()+
  theme(panel.border = element_blank(),
        panel.grid = element_blank(),
        strip.background = element_blank(),
        legend.position = "bottom")

```

## Bootstrap scenario results
Now let's look at the full Monte Carlo simulation results for the influence of bootstrap length.

**THESE ARE INCORRECT AND ARE BEING UPDATED RIGHT NOW...**

```{r}
#| echo: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sim_results <- readRDS("builds/all_scenarios_summarized.Rds")

sim_results <- sim_results[calculation == "SD", ]
head(sim_results)

```

### Speed

Once again, here's our novel effect size 'speed', 1 / x. How do our SAFE estimates of speed and its sampling variance change as we change the number of bootstraps?

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

y_lab <- "Standard deviation of estimate"

theme_SAFE <- theme_bw()+
  theme(panel.border = element_blank(),
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5),
        panel.grid = element_blank(),
        strip.background = element_blank())

facet_labs <- as_labeller(c("point" = "Point estimate",
                            "variance" = "Variance estimate"))

sub_dat <- sim_results[effect_type == "reciprocal", ]

setorder(sub_dat, boots)

ggplot(data = sub_dat, 
            aes(x = boots, y = value, 
                color = sample_size,
                group = sample_size))+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(y_lab)+
  xlab("SAFE bootstrap length")+
  scale_x_log10(breaks = c(1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7))+
  scale_color_scico(name = "Scenario sample size", 
                    palette = "hawaii")+
  facet_wrap(~estimate_of, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("Speed (1 / x)")+
  theme_SAFE+
  theme(legend.position = "bottom")

```

### SMD 4-multivariate normal


```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "SMD_normal", ]
setorder(sub_dat, boots)
sub_dat

ggplot(data = sub_dat, 
            aes(x = boots, y = value, 
                color = sample_size1,
                group = sample_size1))+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(y_lab)+
  xlab("SAFE bootstrap length")+
  scale_x_log10(breaks = c(1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7))+
  scale_color_scico(name = "Scenario sample size", 
                    palette = "hawaii")+
  facet_wrap(~estimate_of, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("SMD (4-multivariate normal SAFE distribution)")+
  theme_SAFE+
  theme(legend.position = "bottom")

```

### SMD 2-multivariate normal and 2-Wishart


```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "SMD_Wishart", ]
setorder(sub_dat, boots)

ggplot(data = sub_dat, 
            aes(x = boots, y = value, 
                color = sample_size1,
                group = sample_size1))+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(y_lab)+
  xlab("SAFE bootstrap length")+
  scale_x_log10(breaks = c(1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7))+
  scale_color_scico(name = "Scenario sample size", 
                    palette = "hawaii")+
  facet_wrap(~estimate_of, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("SMD (2-multivariate normal, 2-Wishart)")+
  theme_SAFE+
  theme(legend.position = "bottom")

```

### lnCVR 4-multivariate normal


```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnCVR_normal", ]
setorder(sub_dat, boots)

ggplot(data = sub_dat, 
            aes(x = boots, y = value, 
                color = sample_size1,
                group = sample_size1))+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(y_lab)+
  xlab("SAFE bootstrap length")+
  scale_x_log10(breaks = c(1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7))+
  scale_color_scico(name = "Scenario sample size", 
                    palette = "hawaii")+
  facet_wrap(~estimate_of, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("lnCVR (4-multivariate normal)")+
  theme_SAFE+
  theme(legend.position = "bottom")

```

### lnCVR 2-multivariate normal and 2-Wishart


```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnCVR_Wishart", ]
setorder(sub_dat, boots)

ggplot(data = sub_dat, 
            aes(x = boots, y = value, 
                color = sample_size1,
                group = sample_size1))+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(y_lab)+
  xlab("SAFE bootstrap length")+
  scale_x_log10(breaks = c(1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7))+
  scale_color_scico(name = "Scenario sample size", 
                    palette = "hawaii")+
  facet_wrap(~estimate_of, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("SMD (2-multivariate normal, 2-Wishart)")+
  theme_SAFE+
  theme(legend.position = "bottom")

```

### lnOR


```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnOR", ]
setorder(sub_dat, boots)

ggplot(data = sub_dat, 
            aes(x = boots, y = value, 
                color = n1,
                group = n1))+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(y_lab)+
  xlab("SAFE bootstrap length")+
  scale_x_log10(breaks = c(1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7))+
  scale_color_scico(name = "Scenario sample size", 
                    palette = "hawaii")+
  facet_wrap(~estimate_of, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("lnOR")+
  theme_SAFE+
  theme(legend.position = "bottom")

```

### lnRR

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnRR", ]
setorder(sub_dat, boots)

ggplot(data = sub_dat, 
            aes(x = boots, y = value, 
                color = n1,
                group = n1))+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(y_lab)+
  xlab("SAFE bootstrap length")+
  scale_x_log10(breaks = c(1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7))+
  scale_color_scico(name = "Scenario sample size", 
                    palette = "hawaii")+
  facet_wrap(~estimate_of, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("lnRR")+
  theme_SAFE+
  theme(legend.position = "bottom")

```

### Hardy Weinberg Disequilibrium

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnHWE_A", ]
setorder(sub_dat, boots)

ggplot(data = sub_dat, 
            aes(x = boots, y = value, 
                color = n,
                group = n))+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(y_lab)+
  xlab("SAFE bootstrap length")+
  scale_x_log10(breaks = c(1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7))+
  scale_color_scico(name = "Scenario sample size", 
                    palette = "hawaii")+
  facet_wrap(~estimate_of, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("Hardy Weinburg Disequilibrium")+
  theme_SAFE+
  theme(legend.position = "bottom")

```
