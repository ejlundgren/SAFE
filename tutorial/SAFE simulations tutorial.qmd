---
title: "SAFE"
subtitle: "step by step online tutorial"
date: "`r Sys.Date()`"
author:
  - name: Shinichi Nakagawa
  - name: Ayumi Mizuno
  - name: Santiago Ortega
  - name: Daniel Noble
  - name: Alistair Senior
  - name: Erick J Lundgren
  - name: many others order TBD
format: 
  html:
    toc: true
    toc-location: left
    toc-depth: 6
    toc-float: true
    toc-expand: true
    toc-title: "**CONTENTS**"
    output-file: "index.html"
    # embed-resources: true
    # code-fold: true
    code-link: true
    code-tools: true
    # number-sections: false
    # bibliography: ./bib/ref.bib
    fontsize: "10"
    mainfont: "Helvetica"
    monofont: "Fira Code"
    # fontcolor: ""
    page-layout: article
    code-overflow: wrap
    df_print: paged
    theme: cosmo
    code-line-numbers: false
    grid:
      margin-width: 120px
# crossref: 
#   fig-title: Figure     # (default is "Figure")
#   tbl-title: Table     # (default is "Table")
#   title-delim: "â€”"     # (default is ":")
#   fig-prefix: Fig.     # (default is "Figure")
#   tbl-prefix: Table.   # (default is "Table")
editor_options: 
  chunk_output_type: console
execute:
  warning: false
  message: false
  tidy: true
---

## Introduction

If you have any questions, errors or bug reports, please feel free to contact Erick Lundgren (erick.lundgren\@gmail.com).

The simulations take a long time to run on a personal computer. We have therefore uploaded all simulation results as .Rds files, though we show exactly how we ran the simulations.

To run the code interactively (instead of just reading this lovely tutorial), do the following:

1.  Clone the github repo: https://github.com/ejlundgren/SAFE.git
2.  Run the code chunks in the SAFE simulations tutorial.qmd while in the R project session or just follow along here on the web :)

## Load libraries

The `groundhog` package ensures that the library versions you use are the same as ours. You will need R version 4.5.0. Be sure to install `groundhog` if it is not already installed with `install.packages()`.

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

# First, clean the environment:
rm(list = ls())

# Now load packages:
# install.packages("groundhog")
library("groundhog")
groundhog.library(pkg = c("data.table", "MASS", "crayon", 
                          "tmvtnorm", "here",
                          "parallel", "foreach", "doSNOW",
                          "ggplot2", "patchwork", "scico"),
                  date = "2025-04-15")

```

# An introduction to SAFE bootstrapping

SAFE bootstrapping is an incredible, seemingly magical, technique to calculate variance estimates for effect sizes, for which sampling variance formulas may not be known. In some cases, it is also more unbiased than traditional plugin formulas for variance and point estimates (i.e., the effect size itself).

## How does it work?

With SAFE bootstrapping, one draws a cloud of *hyperparameters* of all variables used in an effect size formula. You then apply your effect size formula to this cloud. The variance of this transformed cloud, is the sampling variance of your effect size! 

You can then calculate a bias-transformed point estimate by taking the mean of this transformed cloud and subtracting 2 times the point estimate derived simply from the original variables.

Let's demonstrate.

Imagine you want to create an effect size of 'speed' from mean latency time (e.g., time until an event happens). Here let's start with 3 mean latency times and convert to our new 'speed' effect size

```{r}
mean_latency <- c(15, 30, 21)
n <- c(25, 31, 50)
sd <- c(4.6, 3.1, 2.5)

# New effect size:
1/mean_latency
```
The effect size is trivial to calculate. But what is the sampling variance of this effect size, given that each of these measurements was associated with measurement sample size and standard deviation?

You could use calculus to derive a first-order sampling variance formula. Or you could use SAFE. 

### Step 1: draw hyperparameters.
If the word 'hyperparameter' is scary, what we mean is a distribution of the variables associated with the definition formula of the effect size, in this case `latency`. Let's draw 10,000 samples of this hyperparameter from a normal distribution. To avoid using `lapply` or loops, let's just use SAFE to calculate variance for the first mean latency time. We'll calculate standard error from the associated standard deviation and sample size to capture the dispersion of this hyperparameter.

**Shinichi, I don't fully understand why we square root the N for this effect size but not the others**

```{r}
x <- 15 # The mean
sd <- 4.6 # standard deviation
n <- 25 # sample size

cloud <- rnorm(1e6,
               mean = x,
               sd = sd / sqrt(n))
head(cloud)
hist(cloud)

```

### Step 2: transform hyperparameters to target effect size
Now, let's transform this cloud of hyperparameters to 'speed' with our definition formula `1/x`

```{r}
cloud_trans <- 1/cloud
hist(cloud_trans)
```

These values are similar to our transformed effect size:
```{r}
x <- 15

plugin_effect_size <- 1/x

plugin_effect_size

```

### Step 3: Calculate sampling variance

To calculate sampling variance for our effect size we calculate standard error of this transformed cloud. This can be confusing: you do this with `sd`, the standard deviation function because this is a hyperparameter (not a population). Squaring this produces sampling variance:

```{r}
safe_SE <- sd(cloud_trans)

safe_vi <- safe_SE^2

safe_vi
```

Voila! Sampling variance for a novel effect size. 

### Step 4: Calculate bias-corrected effect size

However, given low sample sizes for some measurements, and the knowledge that point estimates can be biased at low N, let's also calculate a bias-corrected point estimate from this cloud of hyperparameters:

```{r}

safe_yi <- (2 * plugin_effect_size) - mean(cloud_trans)

safe_yi

```

Let's compare this to the original point estimate:

```{r}

safe_yi
plugin_effect_size

```
So similar! And potentially less biased. We'll find out below, where we use Monte Carlo simulations to compare the bias of estimates from SAFE to estimates from plugging into a formula.

## Load encapsulated functions

We wrote a function to calculate effect sizes both with plugin estimators and with SAFE. This function can be sourced into the local environment. Let's load the function and then calculate effect sizes, with SAFE, for several examples from the main text. The function is located in the github repo at tutorial/SAFE_function.R. This function returns a data.table (basically a *fast* data.frame) with columns for plugin effect sizes and sampling variances (denoted with `_first` or `_second` based on derivative order) and SAFE effect sizes and sampling variances (denoted with `_safe`). Point estimates (effect sizes) are denoted with `yi_` while sampling variances are denoted with `vi_`.

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

#' *COMMENT OUT FOR RENDERING AND DELETE PRIOR TO PUBLICATION:*
# setwd("tutorial")

source("SAFE_function.R")

# For a single effect size and sampling variance:
eff_size(x1 = 14.5, x2 = 7.9, 
         sd1 = 1.3, sd2 = 2,
         n1 = 20, n2 = 20, 
         effect_type = "lnRoM",
         SAFE = TRUE,
         verbose = TRUE,
         SAFE_boots = 1e6)

```

Or with a vector of raw data:

**UPDATE TO BE PARALLELIZED VERSION**

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

eff_size(x1 = c(14.5, 13, 15.8), 
         x2 = c(7.9, 21, 18.4), 
         sd1 = c(1.3, 2, 1.9), 
         sd2 = c(2, 3.1, 1.4),
         n1 = c(20, 20, 20), 
         n2 = c(20, 15, 18), 
         effect_type = "SMD",
         SAFE = TRUE,
         verbose = FALSE,
         SAFE_boots = 1e6)

```

For a full list of options that eff_size can calculate, please see information by running:

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

eff_size()

```

# How good is SAFE?

We simulated the bias of SAFE calculations versus normal plugin calculations for a variety of common, and less common, effect sizes. We did this across a range of input variables, particularly sample size and the number of SAFE bootstraps. The creation of these scenarios differed for each effect size (based on input variables). The scenarios can be loaded as follows. Let's look at the simulations for lnRoM:

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

scenarios <- readRDS("data/scenarios.Rds")

# Subset scenarios:
guide <- scenarios[effect_type == "lnRoM" &
                     boots == 1e6, ]

guide[, .(effect_type, scenario_id, boots,
                   true_mean1, true_mean2, 
                   true_sd1, true_sd2,
                   sample_size1, sample_size2)]

```

To evaluate effect size performance, we conducted Monte Carlo simulations for each scenario. In these simulations, we created simulated datasets based on true values for each scenario. We then calculated effect sizes and sampling variances (both with plugin formulas and SAFE) for the 'true' values and based on the simulated dataset. We did this 1e5 times for each scenario.

In these Monte Carlo simulation, we were interested in bias, or the difference between the 'true' estimands (i.e., sampling variance and effect sizes) and the estimates (of sampling variance and effect sizes) produced from various methods and applied to the simulated data. We'll explain the difference between estimands, estimators, and estimates below.

To illustrate, we'll do a dummy simulation for lnRoM. Note that the means/sd for each scenario are the same. The only variables that differ are sample sizes. To make this tractable, we'll only run 100 simulations.

To speed things up we will do this in parallel. The function `prepare_cluster()` below can help set things up and provides a progress bar so you don't lose your mind wondering what's going on in there.

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

set.seed(2025)

# Prepare cluster:
prepare_cluster <- function(n,
                             progress_bar = TRUE){
    require("parallel")
    require("foreach")
    require("doSNOW")
    
    nCores <- parallel::detectCores() -1 
    cl <- makeCluster(nCores)
    registerDoSNOW(cl)
    
    # Progress bar
    if(progress_bar == TRUE){
      pb <- txtProgressBar(max = n, style = 3)
      progress <- function(n) setTxtProgressBar(pb, n)
      opts <- list(progress = progress)
      ret <- list(opts, pb, cl)
      names(ret) <- c("options", "progress", "cluster")
    }else{
      ret <- list(cl)
      names(ret) <- c("cluster")
    }

    return(ret)
    
    cat("Pass 'x$options' to .opts in foreach;
      'x$progress' to setTxtProgressBar(x$progress, i);
      'x$cluster' to stopCluster(x$cluster) after foreach")
  }

```

Now we will run 100 simulations to showcase how this method works. The actual simulations had a length of 1e5 and are loaded and visualized in Section **XXXX.** The first part of this code (inside the `lapply`) creates simulated data based on 'true' means and standard deviations. This data is then summarized to a simulation mean and standard deviation. We will then calculate effect sizes and sampling variances for the 'true' values and simulated values. Note that even with only 100 iterations, this can take a minute, so feel free to load the already run dummy dataset in the next code block.

```{r}
#| eval: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

rerun <- F
if(rerun){
  
  monte_carlo_N <- 100
  
  clust_out <- prepare_cluster(n = monte_carlo_N)
  
  res <- foreach(i = 1:monte_carlo_N, 
         .options.snow = clust_out$options,
         .errorhandling = "pass",
         .packages = c("data.table", "MASS", "tmvtnorm")) %dopar% {
           
   # Calculate 'true' values from scenario:
   true_point <- eff_size(x1 = guide$true_mean1, x2 = guide$true_mean2,
                          sd1 = guide$true_sd1,  sd2 = guide$true_sd2,
                          n1 = guide$sample_size1, n2 = guide$sample_size2, 
                          effect_type = "lnRoM",
                          SAFE = FALSE,
                          verbose = FALSE,
                          SAFE_boots = 1e6)
   setnames(true_point,
            c("yi_first", "vi_first", 
              "yi_second", "vi_second"),
            c("true_y_plugin_1st", "true_v_plugin_1st",
              "true_y_plugin_2nd", "true_v_plugin_2nd"))
   
    # Simulate data for each scenario in an lapply: 
   sim_dat <- lapply(1:nrow(guide), function(x){
     
     # Simulate data for guide
     sig <- diag(c(guide$true_sd1[x]^2,
                   guide$true_sd2[x]^2))
     
     means <- c(m1 = guide$true_mean1[x],
                m2 = guide$true_mean2[x])
     
     y <- rtmvnorm(n = max(c(guide$sample_size1[x], guide$sample_size2[x])),
                     mean = means,
                     sigma = sig,
                     lower = rep(0, length(means)),
                     upper = rep(Inf, length(means)),
                     algorithm = "gibbs") |>
       as.data.frame() |>
       setDT()
     names(y) <- c("m1", "m2")
     
     # Filter to number of samples per treatment
     sim_dat <- list(x1 = y[1:guide$sample_size1[x], ]$m1,
                     x2 = y[1:guide$sample_size2[x], ]$m2)
     
     sim_dat <- data.table(sim_mean1 = mean(sim_dat$x1),
                           sim_mean2 = mean(sim_dat$x2),
                           sim_sd1 = sd(sim_dat$x1),
                           sim_sd2 = sd(sim_dat$x2),
                           sim_sample_size1 = length(sim_dat$x1),
                           sim_sample_size2 = length(sim_dat$x2))
     return(sim_dat)
   }) |> rbindlist()
   
  
   out <- eff_size(x1 = sim_dat$sim_mean1, x2 = sim_dat$sim_mean2,
                   sd1 = sim_dat$sim_sd1,  sd2 = sim_dat$sim_sd2,
                   n1 = guide$sample_size1, n2 = guide$sample_size2, 
                   effect_type = "lnRoM",
                   SAFE = TRUE,
                   verbose = FALSE,
                   SAFE_boots = 1e6)
   setnames(out,
            c("yi_first", "vi_first", 
              "yi_second", "vi_second"),
            c("sim_y_plugin_1st", "sim_v_plugin_1st",
              "sim_y_plugin_2nd", "sim_v_plugin_2nd"))
   
   # Store results:
   results <- data.table(guide,
                         sim_dat,
                         true_point,
                         out)
   
   setTxtProgressBar(clust_out$progress, i)
   
   return(results)
  
  }
  stopCluster(clust_out$cluster)
  
  res <- rbindlist(res)  
  head(res)
}
```

Or just load the full simulation (1e5) here:

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

res <- readRDS("data/lnRoM_simulation.Rds")

head(res, 3)

```

## Calculate bias

To interpret the simulation results, it is essential to understand the difference between *estimands*, *estimators*, and *estimates*.

**Estimands** are the 'true' value.

**Estimators** are the methods used to estimate the estimand. What a tongue twister! In our case, the estimators are the 1st order effect size (e.g., definition formula), the 2nd order effect size that has been adjusted (usually using the delta method, except for Hedges' g) to reduce bias, and the SAFE method.

**Estimates** are the estimates of the estimands produced by the estimators.

### Effect size (point estimate) bias

In the case of our effect sizes, there are two estimands that we're interested in estimating: the 'true' effect size (based on the definition formula of the effect size type) and sampling variance. To calculate the bias of our various estimators in estimating effect sizes, we calculate the mean of the estimates from each simulated dataset and subtract the estimand value (the true effect size off the 'true' values).

Here we will calculate bias in our estimates of effect sizes:

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

bias <- function(estimates, estimand){
  return(mean(estimates) - unique(estimand))
}

point.bias <- res[, .(plugin_1st = bias(sim_y_plugin_1st, true_y_plugin_1st),
                      plugin_2nd = bias(sim_y_plugin_2nd, true_y_plugin_1st),
                      safe = bias(yi_safe, true_y_plugin_1st)),
                  by = .(scenario_id, sample_size1, sample_size2)] |> unique()
head(point.bias)

# Melt this to make it plottable:
point.bias.long <- melt(point.bias,
                        id.vars = c("scenario_id", "sample_size1", "sample_size2"),
                        value.name = "bias",
                        variable.name = "estimator")

head(point.bias.long)

# Sort by sample size 
setorder(point.bias.long, sample_size1)

ggplot(data = point.bias.long[sample_size1 == sample_size2, ],
       aes(x = sample_size1, y = bias, color = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(linewidth = 1)+
  xlab("Sample size")+
  ylab("Bias")+
  coord_cartesian(ylim = c(-0.01, 0.01))+
  scale_color_manual("Estimator",
                       labels = c("plugin_1st_bias" = "1st order plugin (definition formula)",
                                  "plugin_2nd_bias" = "2nd order plugin (bias-corrected formula)",
                                  "safe_bias" = "SAFE bootstrapping"),
                       values = c("plugin_1st" = "#A8DADC",
                                   "plugin_2nd" = "#1D3557",
                                   "safe" = "#E63946"))+
  theme_bw()+
  theme(panel.border = element_blank(),
        panel.grid = element_blank(),
        legend.position = "bottom")

```

This indicates that the least biased estimator is the first order definition formula (light blue). SAFE (red) and the 2nd order plugin (navy blue) perform similarly. These bias values are incredibly small, indicating that all options are fair, except for at low sample sizes, when the first-order definition formula is quite biased.

### Sampling variance bias

Interestingly, there is no way to know the 'true' estimand for sampling variance. **WHICH I DON'T FULLY UNDERSTAND**. To calculate bias for our sampling variance estimates, we actually calculate the variance in point estimates for each estimator and use *each* of these as the estimand. With 3 estimators, and thus 3 estimands, we'll thus end up with 9 calculations of bias.

Since we're interested in relative bias (**Not entirely sure why**), we'll calculate bias as above but divide by the estimand and multiply by 100.

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

# First, calculate variance in point estimates as our 'estimand'
res[, var_estimand_1st := var(sim_y_plugin_1st), 
    by = .(scenario_id)]
res[, var_estimand_2nd := var(sim_y_plugin_2nd), 
    by = .(scenario_id)]
res[, var_estimand_SAFE := var(yi_safe), 
    by = .(scenario_id)]

# To make this easier to read, we'll encapsulate the relative bias in a function:
relative_bias <- function(estimates,
                          estimand){
  return(((mean(estimates) - unique(estimand)) / estimand) * 100)
}

# Now summarize and calculate relative bias per scenario ID
var.bias <- res[, .(SAFE_estimate.1st_estimand = relative_bias(vi_safe, var_estimand_1st),
                    SAFE_estimate.2nd_estimand = relative_bias(vi_safe, var_estimand_2nd),
                    SAFE_estimate.SAFE_estimand = relative_bias(vi_safe, var_estimand_SAFE),
                    plugin_1st_estimate.1st_estimand = relative_bias(sim_v_plugin_1st, var_estimand_1st),
                    plugin_1st_estimate.2nd_estimand = relative_bias(sim_v_plugin_1st, var_estimand_2nd),
                    plugin_1st_estimate.SAFE_estimand = relative_bias(sim_v_plugin_1st, var_estimand_SAFE),
                    plugin_2nd_estimate.1st_estimand = relative_bias(sim_v_plugin_2nd, var_estimand_1st),
                    plugin_2nd_estimate.2nd_estimand = relative_bias(sim_v_plugin_2nd, var_estimand_2nd),
                    plugin_2nd_estimate.SAFE_estimand = relative_bias(sim_v_plugin_2nd, var_estimand_SAFE)),
    by = .(scenario_id, sample_size1, sample_size2)] |> unique()


# Now melt:
var.bias.long <- melt(var.bias,
                      id.vars = c("scenario_id", "sample_size1", "sample_size2"))
head(var.bias.long)

# Split the 'variable' into estimator and estimand for plotting
var.bias.long[, c("Estimator", "Estimand") := tstrsplit(variable, ".", fixed = TRUE)]

# Sort the dataset by sample size
setorder(var.bias.long, sample_size1)

# Plot
ggplot(data = var.bias.long[sample_size1 == sample_size2, ], 
       aes(x = sample_size1, y = value, color = Estimator))+
    geom_path(linewidth = 1)+
  geom_hline(yintercept = 0)+
  xlab("Sample size")+
  ylab("Relative bias (%)")+
  scale_color_manual("Estimator",
                     labels = c("plugin_1st_estimate" = "1st order plugin (definition formula)",
                                  "plugin_2nd_estimate" = "2nd order plugin (bias-corrected formula)",
                                  "SAFE_estimate" = "SAFE bootstrapping"),
                     values = c("plugin_1st_estimate" = "#A8DADC",
                               "plugin_2nd_estimate" = "#1D3557",
                               "SAFE_estimate" = "#E63946"))+
  facet_wrap(~Estimand,
             ncol = 1,
             labeller = as_labeller(c("1st_estimand" = "1st order plugin estimand\n(definition formula)",
                                    "2nd_estimand" = "2nd order plugin estimand",
                                    "SAFE_estimand" = "SAFE estimand")))+
  theme_bw()+
  theme(panel.border = element_blank(),
        panel.grid = element_blank(),
        strip.background = element_blank(),
        legend.position = "bottom")

```

We see here that SAFE (red) is slightly more biased, but in a conservative direction, than the other estimators.

## Plot all simulations results

Now let's look at the rest of the simulation results.

```{r}
#| echo: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sim_results <- readRDS("data/all_scenarios_summarized.Rds")
sim_results <- sim_results[boots == 1e6, ]

```

### Speed

This was our dummy effect size in the beginning. How do the point and variance estimates calculated by SAFE compare to just calculating 1 / x for point estimates? 

Moreover, we compared the variance estimates from SAFE to variance estimates produced by a 1st-order derivative sampling variance formula derived with the delta method (denoted 1st order plugin here). Let's see which did better!

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

var_lab <- "Relative bias of\nvariance estimates (%)"
point_lab <- "Bias of point\nestimates"

theme_SAFE <- theme_bw()+
  theme(panel.border = element_blank(),
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5),
        panel.grid = element_blank(),
        strip.background = element_blank())

labs = c("plugin_1st" = "1st order plugin",
           "plugin_2nd" = "2nd order plugin",
           "safe" = "SAFE")

pal = c("plugin_1st" = "#A8DADC",
           "plugin_2nd" = "#1D3557",
           "safe" = "#E63946")
pt_size <- 2

facet_labs <- as_labeller(c("plugin_1st_mc" = "Monte Carlo 1st order plugin estimand",
                            "plugin_2nd_mc" = "Monte Carlo 2nd order plugin estimand",
                            "safe_mc" = "Monte Carlo SAFE variance estimand",
                            "true_1st" = "True 1st order point estimand",
                            "true_2nd" = "True 2nd order point estimand"))

sub_dat <- sim_results[effect_type == "reciprocal", ]

setorder(sub_dat, sample_size)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias"), ], 
            aes(x = sample_size, y = value, color = estimator,
                group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             labeller = facet_labs)+
  coord_cartesian(ylim = c(-0.0001, 0.0001))+
  ggtitle("Speed (1 / x)")+
  theme_SAFE+
  theme(legend.position = "none") 

p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias"), ], 
             aes(x = sample_size, y = value, color = estimator,
                 group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             labeller = facet_labs,
             nrow = 2)+
  coord_cartesian(ylim = c(-5, 5))+
  theme_SAFE+
  theme(legend.position = "bottom")

p.point + p.variance + plot_layout(ncol = 1, heights = c(1/3, 2/3))

```

### SMD 4-multivariate normal

The SAFE estimator for this effect size was calculated with a multivariate normal distribution for both mean and SD.

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "SMD_normal", ]

setorder(sub_dat, sample_size1)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias") & sample_size_ratio == 1, ], 
                  aes(x = sample_size1, y = value, color = estimator,
                      group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             labeller = facet_labs)+
  coord_cartesian(ylim = c(-0.1, 0.1))+
  ggtitle("SMD")+
  theme_SAFE+
  theme(legend.position = "none") 

#
p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias") & sample_size_ratio == 1, ], 
                     aes(x = sample_size1, y = value, color = estimator,
                         group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = c(plugin_1st = "Cohen's d", 
                                plugin_2nd = "Hedges' g", 
                                safe = "SAFE"))+
  coord_cartesian(ylim = c(-30, 30))+
  facet_wrap(~estimand, 
             ncol = 1,
             labeller = as_labeller(c("plugin_1st_mc" = "Monte Carlo Cohen's d estimand",
                                      "plugin_2nd_mc" = "Monte Carlo Hedges' g estimand",
                                      "safe_mc" = "Monte Carlo SAFE variance estimand",
                                      "true_1st" = "True Cohen's d point estimand",
                                      "true_2nd" = "True Hedges' g point estimand")))+
  theme_SAFE+
  theme(legend.position = "bottom")

p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```

### SMD 2-multivariate normal and 2-Wishart

With this estimator, the SAFE calculation used the normal distribution for the two means but the Wishart distribution to estimate the SD.

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

# sub_dat <- sim_results[effect_type == "SMD_Wishart", ]
# setorder(sub_dat, sample_size1)
# 
# p.point <- ggplot(data = sub_dat[calculation %in% c("bias") & sample_size_ratio == 1, ], 
#                   aes(x = sample_size1, y = value, color = estimator,
#                       group = estimator))+
#   geom_hline(yintercept = 0)+
#   geom_path(lwd = 1)+
  # geom_point(size = pt_size)+
#   ylab(point_lab)+
#   xlab("Sample size")+
#   scale_color_manual(name = "Estimator", 
#                      values = pal,
#                      labels = labs)+
#   facet_wrap(~estimand, 
#              labeller = facet_labs)+
#   coord_cartesian(ylim = c(-0.1, 0.1))+
#   ggtitle("SMD (x1 - x2) / pooled SD",
#           subtitle = "with n1==n2")+
#   theme_SAFE+
#   theme(legend.position = "none") 
# 
# #
# p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias") & sample_size_ratio == 1, ], 
#                      aes(x = sample_size1, y = value, color = estimator,
#                          group = estimator))+
#   geom_hline(yintercept = 0)+
#   geom_path(lwd = 1)+
  # geom_point(size = pt_size)+
#   ylab(var_lab)+
#   xlab("Sample size")+
#   scale_color_manual(name = "Estimator", 
#                      values = pal,
#                      labels = c(plugin_1st = "Cohen's d", 
#                                 plugin_2nd = "Hedges' g", 
#                                 safe = "SAFE"))+
#   facet_wrap(~estimand, 
#              ncol = 1,
#              labeller = as_labeller(c("plugin_1st_mc" = "Monte Carlo Cohen's d estimand",
#                                       "plugin_2nd_mc" = "Monte Carlo Hedges' g estimand",
#                                       "safe_mc" = "Monte Carlo SAFE variance estimand",
#                                       "true_1st" = "True Cohen's d point estimand",
#                                       "true_2nd" = "True Hedges' g point estimand")))+
#   coord_cartesian(ylim = c(-60, 60))+
#   theme_SAFE+
#   theme(legend.position = "bottom")
# 
# p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```

### lnCVR 4-multivariate normal

The SAFE estimator for this effect size was calculated with a multivariate normal distribution for both mean and SD.

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnCVR_normal", ]
setorder(sub_dat, sample_size1)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias") & 
                                   sample_size_ratio == 1, ], 
                  aes(x = sample_size1, y = value, color = estimator,
                      group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             labeller = facet_labs)+
  coord_cartesian(ylim = c(-0.05, 0.05))+
  ggtitle("lnCVR")+
  theme_SAFE+
  theme(legend.position = "none") 

#
p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias") & sample_size_ratio == 1, ], 
                     aes(x = sample_size1, y = value, color = estimator,
                         group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             ncol = 1,
             labeller = facet_labs)+
  coord_cartesian(ylim = c(-60, 60))+
  theme_SAFE+
  theme(legend.position = "bottom")

p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```

### lnCVR 2-multivariate normal and 2-Wishart

The SAFE estimator for this effect size was calculated with a multivariate normal distribution for both mean and SD.

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

# sub_dat <- sim_results[effect_type == "lnCVR_Wishart", ]
# setorder(sub_dat, sample_size1)
# 
# p.point <- ggplot(data = sub_dat[calculation %in% c("bias") & 
#                                    sample_size_ratio == 1, ], 
#                   aes(x = sample_size1, y = value, color = estimator,
#                       group = estimator))+
#   geom_hline(yintercept = 0)+
#   geom_path(lwd = 1)+
  # geom_point(size = pt_size)+
#   ylab(point_lab)+
#   xlab("Sample size")+
#   scale_color_manual(name = "Estimator", 
#                      values = pal,
#                      labels = labs)+
#   coord_cartesian(ylim = c(-0.05, 0.05))+
#   facet_wrap(~estimand, 
#              labeller = facet_labs)+
#   ggtitle("lnCVR",
#           subtitle = "with n1==n2")+
#   theme_SAFE+
#   theme(legend.position = "none") #, legend.position.inside = c(.85, .85)
# 
# #
# p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias") & sample_size_ratio == 1, ], 
#                      aes(x = sample_size1, y = value, color = estimator,
#                          group = estimator))+
#   geom_hline(yintercept = 0)+
#   geom_path(lwd = 1)+
  # geom_point(size = pt_size)+
#   ylab(var_lab)+
#   xlab("Sample size")+
#   scale_color_manual(name = "Estimator", 
#                      values = pal,
#                      labels = labs)+
#   coord_cartesian(ylim = c(-30, 30))+
#   facet_wrap(~estimand, 
#              ncol = 1,
#              labeller = facet_labs)+
#   theme_SAFE+
#   theme(legend.position = "bottom")
# 
# p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```

### lnOR

In this effect size estimation, the SAFE calculation used a binomial distribution to draw random binomial samples for 'a' and 'c'.

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnOR", ]
setorder(sub_dat, n1)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias"), ], 
                  aes(x = n1, y = value, color = estimator,
                      group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand,
             labeller = facet_labs)+
  coord_cartesian(ylim = c(-1, 1))+
  ggtitle("lnOR")+
  theme_SAFE+
  theme(legend.position = "none") 

#
p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias"), ], 
                     aes(x = n1, y = value, color = estimator,
                         group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             ncol = 1,
             labeller = facet_labs)+
  coord_cartesian(ylim = c(-90, 90))+
  theme_SAFE+
  theme(legend.position = "bottom")

p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```

### lnRR

In this effect size estimation, the SAFE calculation drew 'a' and 'c' from a binomial distribution.

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnRR", ]
setorder(sub_dat, n1)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias") , ], 
                  aes(x = n1, y = value, color = estimator,
                      group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             labeller = facet_labs)+
  coord_cartesian(ylim = c(-.1, .1))+
  ggtitle("lnRR")+
  theme_SAFE+
  theme(legend.position = "none") 

#
p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias"), ], 
                     aes(x = n1, y = value, color = estimator,
                         group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             ncol = 1,
             labeller = facet_labs)+
  coord_cartesian(ylim = c(-30, 30))+
  theme_SAFE+
  theme(legend.position = "bottom")

p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```

### Hardy Weinberg Disequilibrium

In this effect size estimation, the SAFE calculation drew 'n_AA', 'n_Aa', and 'n_aa' from a binomial distribution.

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnHWE_A", ]
setorder(sub_dat, n)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias"), ], 
                  aes(x = n, y = value, color = estimator,
                      group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             labeller = facet_labs)+
  coord_cartesian(ylim = c(-0.1, 0.1))+
  ggtitle("lnHWD")+
  theme_SAFE+
  theme(legend.position = "none") 

#
p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias") & 
                                   p_AA == 0.25 & p_aa == 0.25 & p_Aa == 0.5, ], 
                     aes(x = n, y = value, color = estimator,
                         group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             ncol = 1,
             labeller = facet_labs)+
    coord_cartesian(ylim = c(-15, 15))+
  theme_SAFE+
  theme(legend.position = "bottom")


p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```

# How many SAFE bootstraps?
The SAFE method relies on bootstrapping to calculate effect size point estimates and sampling variance. It's sort of magical how well it works! But, how many bootstraps are necessary? Let's find out by doing another Monte Carlo simulation, again of lnRoM. This time, instead of calculating bias, we'll look at the standard deviation of the point and sampling variance estimates as we change the number of bootstraps.

Let's two bootstrap lengths: 100 and 1,000. We'll run the Monte Carlo simulation itself 1,000 times just to make this easy. (See below for full 1e5 simulation results)

```{r}

  # Create some scenarios based on combinations of sample size and boot-length
  scenario <- CJ(effect_type = "lnRoM",
                 true_mean1 = 13.4, true_sd1 = 4.6,
                 true_mean2 = 16.1, true_sd2 = 3.9,
                 sample_size1 = c(5, 10, 150),
                 boots = c(100, 1000))
  scenario[, sample_size2 := sample_size1]
  scenario

```

Now let's run this in a foreach loop. If you'd rather not run this on your machine, this will load the finished result below if `run` == FALSE.

```{r}
run <- FALSE
if(run == TRUE){
  out <- list()
  sub_scenario <- c()
  N <- 1000
  clust_out <- prepare_cluster(n = N, 
                               progress_bar = FALSE)
  res <- list()
  
  
  res <- foreach(i = 1:N, 
                .options.snow = clust_out$options,
               .errorhandling = "stop",
               .packages = c("data.table", "MASS",
                             "crayon", "tmvtnorm")) %dopar% {
                               
   sub_scenario <- scenario[boots == 100, ]                                        
   out[[1]] <- eff_size(x1 = sub_scenario$true_mean1,
                   x2 = sub_scenario$true_mean2,
                   sd1 = sub_scenario$true_sd1,
                   sd2 = sub_scenario$true_sd2,
                   n1 = sub_scenario$sample_size1,
                   n2 = sub_scenario$sample_size2,
                   effect_type = "SMD",
                   SAFE = TRUE,
                   verbose = FALSE,
                   SAFE_boots = unique(sub_scenario$boots)) 
    out[[1]] <- data.table(out[[1]],
                           sub_scenario[, .(boots, sample_size1)])
    out[[1]]
    
    sub_scenario <- scenario[boots == 1000, ]                                        
    out[[2]] <- eff_size(x1 = sub_scenario$true_mean1,
                   x2 = sub_scenario$true_mean2,
                   sd1 = sub_scenario$true_sd1,
                   sd2 = sub_scenario$true_sd2,
                   n1 = sub_scenario$sample_size1,
                   n2 = sub_scenario$sample_size2,
                   effect_type = "SMD",
                   SAFE = TRUE,
                   verbose = FALSE,
                   SAFE_boots = unique(sub_scenario$boots)) 
     out[[2]] <- data.table(out[[2]],
                           sub_scenario[, .(boots, sample_size1)])
     out[[2]]   
    
     return(rbindlist(out))
  }
  
  res.dt <- rbindlist(res)
  res.dt
  
  saveRDS(res.dt, "data/dummy_bootstrap_simulation.Rds")
}else{
  res.dt <- readRDS("data/dummy_bootstrap_simulation.Rds")
}
```

Let's look at the dispersion of the SAFE estimates as a function of sample size and bootstrap length

```{r}

# First, the point estimates:
ggplot(data = res.dt, 
       aes(x = as.factor(sample_size1), y = yi_safe, 
           fill = boots,
           group = interaction(sample_size1, boots)))+
  geom_jitter(alpha = .5, shape = 21,
              position = position_jitterdodge(dodge.width = 1))+
  geom_violin(position = position_dodge(width = 1))+
  ylab("SAFE Point Estimate")+
  xlab("Scenario sample size")+
  scale_fill_scico("Number of SAFE bootstraps",
                   palette = "hawaii")+
  theme_bw()+
  theme(panel.border = element_blank(),
        panel.grid = element_blank(),
        strip.background = element_blank(),
        legend.position = "bottom")

```

Now let's look at the variance estimates:

```{r}
ggplot(data = res.dt, 
       aes(x = as.factor(sample_size1), y = vi_safe, 
           fill = boots,
           group = interaction(sample_size1, boots)))+
  geom_jitter(alpha = .5, shape = 21,
              position = position_jitterdodge(dodge.width = 1))+
  geom_violin(position = position_dodge(width = 1))+
  ylab("SAFE Variance Estimate")+
  xlab("Scenario sample size")+
  scale_fill_scico("Number of SAFE bootstraps",
                   palette = "hawaii")+
  theme_bw()+
  theme(panel.border = element_blank(),
        panel.grid = element_blank(),
        strip.background = element_blank(),
        legend.position = "bottom")


```

Looks like the dispersion in estimates is shaped by number of SAFE bootstraps and improves considerably with 1,000 bootstraps, especially at low sample sizes. Another way to visualize this (which we'll use below in the actual 1e5 simulations) is to plot the standard deviation.

```{r}

res.summary <- res.dt[, .(sd_point_estimate = sd(yi_safe),
                       sd_variance_estimate = sd(vi_safe)),
                   by = .(sample_size1, boots)]
res.summary

# Let's melt this to make a single plot:
res.summary.mlt <- melt(res.summary,
                        id.vars = c("sample_size1", "boots"))
res.summary.mlt
setorder(res.summary.mlt, boots)

ggplot(data = res.summary.mlt,
       aes(x = boots, y = value, color = sample_size1,
           group = interaction(sample_size1)))+
  geom_path()+
  geom_point(size = pt_size)+
  facet_wrap(~variable,
             labeller = as_labeller(c("sd_point_estimate" = "Point estimate",
                                      "sd_variance_estimate" = "Variance estimate")))+
  scale_color_scico("Scenario sample size",
                   palette = "hawaii")+
  xlab("SAFE bootstrap length")+
  ylab("Standard deviation of estimate")+
  theme_bw()+
  theme(panel.border = element_blank(),
        panel.grid = element_blank(),
        strip.background = element_blank(),
        legend.position = "bottom")

```

## Bootstrap scenario results
Now let's look at the full Monte Carlo simulation results for the influence of bootstrap length.

```{r}
#| echo: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sim_results <- readRDS("data/all_scenarios_summarized.Rds")

sim_results <- sim_results[calculation == "SD", ]
head(sim_results)

```

### Reciprocal

1 / x

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

y_lab <- "Standard deviation of estimate"

theme_SAFE <- theme_bw()+
  theme(panel.border = element_blank(),
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5),
        panel.grid = element_blank(),
        strip.background = element_blank())

facet_labs <- as_labeller(c("point" = "Point estimate",
                            "variance" = "Variance estimate"))

sub_dat <- sim_results[effect_type == "reciprocal", ]

setorder(sub_dat, boots)

ggplot(data = sub_dat, 
            aes(x = boots, y = value, 
                color = sample_size,
                group = sample_size))+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(y_lab)+
  xlab("SAFE bootstrap length")+
  scale_x_log10(breaks = c(1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7))+
  scale_color_scico(name = "Scenario sample size", 
                    palette = "hawaii")+
  facet_wrap(~estimate_of, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("Reciprocal (1 / x)")+
  theme_SAFE+
  theme(legend.position = "bottom")

```

### SMD 4-multivariate normal

The SAFE estimator for this effect size was calculated with a multivariate normal distribution for both mean and SD.

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "SMD_normal", ]
setorder(sub_dat, boots)
sub_dat

ggplot(data = sub_dat, 
            aes(x = boots, y = value, 
                color = sample_size1,
                group = sample_size1))+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(y_lab)+
  xlab("SAFE bootstrap length")+
  scale_x_log10(breaks = c(1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7))+
  scale_color_scico(name = "Scenario sample size", 
                    palette = "hawaii")+
  facet_wrap(~estimate_of, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("SMD (4-multivariate normal SAFE distribution)")+
  theme_SAFE+
  theme(legend.position = "bottom")

```

### SMD 2-multivariate normal and 2-Wishart

With this estimator, the SAFE calculation used the normal distribution for the two means but the Wishart distribution to estimate the SD.

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "SMD_Wishart", ]
setorder(sub_dat, boots)

ggplot(data = sub_dat, 
            aes(x = boots, y = value, 
                color = sample_size1,
                group = sample_size1))+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(y_lab)+
  xlab("SAFE bootstrap length")+
  scale_x_log10(breaks = c(1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7))+
  scale_color_scico(name = "Scenario sample size", 
                    palette = "hawaii")+
  facet_wrap(~estimate_of, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("SMD (2-multivariate normal, 2-Wishart)")+
  theme_SAFE+
  theme(legend.position = "bottom")

```

### lnCVR 4-multivariate normal

The SAFE estimator for this effect size was calculated with a multivariate normal distribution for both mean and SD.

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnCVR_normal", ]
setorder(sub_dat, boots)

ggplot(data = sub_dat, 
            aes(x = boots, y = value, 
                color = sample_size1,
                group = sample_size1))+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(y_lab)+
  xlab("SAFE bootstrap length")+
  scale_x_log10(breaks = c(1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7))+
  scale_color_scico(name = "Scenario sample size", 
                    palette = "hawaii")+
  facet_wrap(~estimate_of, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("lnCVR (4-multivariate normal)")+
  theme_SAFE+
  theme(legend.position = "bottom")

```

### lnCVR 2-multivariate normal and 2-Wishart

The SAFE estimator for this effect size was calculated with a multivariate normal distribution for both mean and SD.

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnCVR_Wishart", ]
setorder(sub_dat, boots)

ggplot(data = sub_dat, 
            aes(x = boots, y = value, 
                color = sample_size1,
                group = sample_size1))+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(y_lab)+
  xlab("SAFE bootstrap length")+
  scale_x_log10(breaks = c(1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7))+
  scale_color_scico(name = "Scenario sample size", 
                    palette = "hawaii")+
  facet_wrap(~estimate_of, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("SMD (2-multivariate normal, 2-Wishart)")+
  theme_SAFE+
  theme(legend.position = "bottom")

```

### lnOR

In this effect size estimation, the SAFE calculation used a binomial distribution to draw random binomial samples for 'a' and 'c'.

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnOR", ]
setorder(sub_dat, boots)

ggplot(data = sub_dat, 
            aes(x = boots, y = value, 
                color = n1,
                group = n1))+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(y_lab)+
  xlab("SAFE bootstrap length")+
  scale_x_log10(breaks = c(1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7))+
  scale_color_scico(name = "Scenario sample size", 
                    palette = "hawaii")+
  facet_wrap(~estimate_of, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("lnOR")+
  theme_SAFE+
  theme(legend.position = "bottom")

```

### lnRR

In this effect size estimation, the SAFE calculation drew 'a' and 'c' from a binomial distribution.

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnRR", ]
setorder(sub_dat, boots)

ggplot(data = sub_dat, 
            aes(x = boots, y = value, 
                color = n1,
                group = n1))+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(y_lab)+
  xlab("SAFE bootstrap length")+
  scale_x_log10(breaks = c(1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7))+
  scale_color_scico(name = "Scenario sample size", 
                    palette = "hawaii")+
  facet_wrap(~estimate_of, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("lnRR")+
  theme_SAFE+
  theme(legend.position = "bottom")

```

### Hardy Weinberg Disequilibrium

In this effect size estimation, the SAFE calculation drew 'n_AA', 'n_Aa', and 'n_aa' from a binomial distribution.

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnHWE_A", ]
setorder(sub_dat, boots)

ggplot(data = sub_dat, 
            aes(x = boots, y = value, 
                color = n,
                group = n))+
  geom_path(lwd = 1)+
  geom_point(size = pt_size)+
  ylab(y_lab)+
  xlab("SAFE bootstrap length")+
  scale_x_log10(breaks = c(1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7))+
  scale_color_scico(name = "Scenario sample size", 
                    palette = "hawaii")+
  facet_wrap(~estimate_of, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("Hardy Weinburg Disequilibrium")+
  theme_SAFE+
  theme(legend.position = "bottom")

```
