---
title: "SAFE simulations"
subtitle: "step by step online tutorial"
date: "`r Sys.Date()`"
author:
  - name: Shinichi Nakagawa
  - name: Ayumi Mizuno
  - name: Santiago Ortega
  - name: Daniel Noble
  - name: Alistair Senior
  - name: Erick J Lundgren
  - name: many others order TBD
format: 
  html:
    toc: true
    toc-location: left
    toc-depth: 6
    toc-float: true
    toc-expand: true
    toc-title: "**CONTENTS**"
    output-file: "index.html"
    # embed-resources: true
    # code-fold: true
    code-link: true
    code-tools: true
    # number-sections: false
    # bibliography: ./bib/ref.bib
    fontsize: "10"
    mainfont: "Helvetica"
    monofont: "Fira Code"
    # fontcolor: ""
    page-layout: article
    code-overflow: wrap
    df_print: paged
    theme: cosmo
    code-line-numbers: false
    grid:
      margin-width: 120px
# crossref: 
#   fig-title: Figure     # (default is "Figure")
#   tbl-title: Table     # (default is "Table")
#   title-delim: "â€”"     # (default is ":")
#   fig-prefix: Fig.     # (default is "Figure")
#   tbl-prefix: Table.   # (default is "Table")
editor_options: 
  chunk_output_type: console
execute:
  warning: false
  message: false
  tidy: true
---

## Introduction

If you have any questions, errors or bug reports, please feel free to contact Erick Lundgren (erick.lundgren\@gmail.com).

The simulations take a long time to run on a personal computer. We have therefore uploaded all simulation results as .Rds files, though we show exactly how we ran the simulations.

To run the code interactively (instead of just reading this lovely tutorial), do the following:

1.  Clone the github repo: https://github.com/ejlundgren/SAFE.git
2.  Download the raw simulation from **XXXXX** and place one directory level above the github project repo.
3.  Run the code chunks in the SAFE simulations tutorial.qmd while in the R project session.

## Load libraries

The `groundhog` package ensures that the library versions you use are the same as ours. You will need R version 4.5.0. Be sure to install `groundhog` if it is not already installed with `install.packages()`.

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

# First, clean the environment:
rm(list = ls())

# Now load packages:
# install.packages("groundhog")
library("groundhog")
groundhog.library(pkg = c("data.table", "MASS", "crayon", 
                          "tmvtnorm", "here",
                          "parallel", "foreach", "doSNOW",
                          "ggplot2", "patchwork"),
                  date = "2025-04-15")

```

## Load encapsulated functions

We wrote a function to calculate effect sizes both with plugin estimators and with SAFE. This function can be sourced into the local environment. Let's load the function and then calculate effect sizes, with SAFE, for several examples from the main text. The function is located in the github repo at tutorial/SAFE_function.R. This function returns a data.table (basically a *fast* data.frame) with columns for plugin effect sizes and sampling variances (denoted with `_first` or `_second` based on derivative order) and SAFE effect sizes and sampling variances (denoted with `_safe`). Point estimates (effect sizes) are denoted with `yi_` while sampling variances are denoted with `vi_`.

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

# COMMENT OUT FOR RENDERING AND DELETE PRIOR TO PUBLICATION:
# setwd("tutorial")

source("SAFE_function.R")

# For a single effect size and sampling variance:
eff_size(x1 = 14.5, x2 = 7.9, 
         sd1 = 1.3, sd2 = 2,
         n1 = 20, n2 = 20, 
         effect_type = "lnRoM",
         SAFE = TRUE,
         parallelize = TRUE)
```

Or with a vector of raw data:

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

eff_size(x1 = c(14.5, 13, 15.8), 
         x2 = c(7.9, 21, 18.4), 
         sd1 = c(1.3, 2, 1.9), 
         sd2 = c(2, 3.1, 1.4),
         n1 = c(20, 20, 20), 
         n2 = c(20, 15, 18), 
         effect_type = "SMD",
         SAFE = TRUE,
         parallelize = TRUE)

```

For a full list of options that eff_size can calculate, please see information by running:

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

eff_size()

```

## Run sample simulation

We simulated the bias of SAFE calculations versus normal plugin calculations for a variety of common, and less common, effect sizes. We did this across a range of input variables, particularly sample size. The creation of these scenarios differed for each effect size (based on input variables). The scenarios can be loaded as follows. Let's look at the simulations for lnRoM:

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

scenarios <- readRDS("data/scenarios.Rds")

# Subset scenarios:
guide <- scenarios[effect_type == "lnRoM" & sample_size_ratio == 1, ]

guide[, .(effect_type, scenario_id, 
                   true_mean1, true_mean2, 
                   true_sd1, true_sd2, 
                   sample_size1, sample_size2)]

```

To evaluate effect size performance, we conducted Monte Carlo simulations for each scenario. In these simulations, we created simulated datasets based on true values for each scenario. We then calculated effect sizes and sampling variances (both with plugin formulas and SAFE) for the 'true' values and based on the simulated dataset. We did this 1e5 times for each scenario.

In these Monte Carlo simulation, we were interested in bias, or the difference between the 'true' estimands (i.e., sampling variance and effect sizes) and the estimates (of sampling variance and effect sizes) produced from various methods and applied to the simulated data. We'll explain the difference between estimands, estimators, and estimates below.

To illustrate, we'll do a dummy simulation for lnRoM. Note that the means/sd for each scenario are the same. The only variables that differ are sample sizes. To make this tractable, we'll only run 100 simulations.

To speed things up we will do this in parallel. The function `prepare_cluster()` below can help set things up and provides a progress bar so you don't lose your mind wondering what's going on in there.

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

set.seed(2025)

# Prepare cluster:
prepare_cluster <- function(n){
  require("parallel")
  require("foreach")
  require("doSNOW")
  
  nCores <- parallel::detectCores() -1 
  cl <- makeCluster(nCores)
  registerDoSNOW(cl)
  
  # Progress bar
  pb <- txtProgressBar(max = n, style = 3)
  progress <- function(n) setTxtProgressBar(pb, n)
  opts <- list(progress = progress)
  
  ret <- list(opts, pb, cl)
  names(ret) <- c("options", "progress", "cluster")
  return(ret)
  
  cat("Pass 'x$options' to .opts in foreach;
      'x$progress' to setTxtProgressBar(x$progress, i);
      'x$cluster' to stopCluster(x$cluster) after foreach")
}

```

Now we will run 100 simulations to showcase how this method works. The actual simulations had a length of 1e5 and are loaded and visualized in Section **XXXX.** The first part of this code (inside the `lapply`) creates simulated data based on 'true' means and standard deviations. This data is then summarized to a simulation mean and standard deviation. We will then calculate effect sizes and sampling variances for the 'true' values and simulated values. Note that even with only 100 iterations, this can take a minute. Feel free to skip this step and load the actual 1e5 processed simulation in the subsequent code block.

```{r}
#| eval: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

rerun <- F
if(rerun){
  
  clust_out <- prepare_cluster(n = 100)
  
  res <- foreach(i = 1:100, 
         .options.snow = clust_out$options,
         .errorhandling = "pass",
         .packages = c("data.table", "MASS", "tmvtnorm")) %dopar% {
           
  # Simulate data for each scenario in an lapply: 
   sim_dat <- lapply(1:nrow(guide), function(x){
     
     # Simulate data for guide
     sig <- diag(c(guide$true_sd1[x]^2,
                   guide$true_sd2[x]^2))
     
     means <- c(m1 = guide$true_mean1[x],
                m2 = guide$true_mean2[x])
     
     y <- rtmvnorm(n = max(c(guide$sample_size1[x], guide$sample_size2[x])),
                     mean = means,
                     sigma = sig,
                     lower = rep(0, length(means)),
                     upper = rep(Inf, length(means)),
                     algorithm = "gibbs") |>
       as.data.frame() |>
       setDT()
     names(y) <- c("m1", "m2")
     
     # Filter to number of samples per treatment
     sim_dat <- list(x1 = y[1:guide$sample_size1[x], ]$m1,
                     x2 = y[1:guide$sample_size2[x], ]$m2)
     
     sim_dat <- data.table(sim_mean1 = mean(sim_dat$x1),
                           sim_mean2 = mean(sim_dat$x2),
                           sim_sd1 = sd(sim_dat$x1),
                           sim_sd2 = sd(sim_dat$x2),
                           sim_n1 = length(sim_dat$x1),
                           sim_n2 = length(sim_dat$x2))
     return(sim_dat)
   }) |> rbindlist()
   
   #
   true_point <- eff_size(x1 = guide$true_mean1, x2 = guide$true_mean2,
                          sd1 = guide$true_sd1,  sd2 = guide$true_sd2,
                          n1 = guide$sample_size1, n2 = guide$sample_size2, 
                          effect_type = "lnRoM",
                          SAFE = FALSE,
                          verbose = FALSE,
                          parallelize = FALSE,
                          SAFE_boots = 1e6)
   setnames(true_point,
            c("yi_first", "vi_first", 
              "yi_second", "vi_second"),
            c("true_y_plugin_1st", "true_v_plugin_1st",
              "true_y_plugin_2nd", "true_v_plugin_2nd"))
   
   out <- eff_size(x1 = sim_dat$sim_mean1, x2 = sim_dat$sim_mean2,
                   sd1 = sim_dat$sim_sd1,  sd2 = sim_dat$sim_sd2,
                   n1 = guide$sample_size1, n2 = guide$sample_size2, 
                   effect_type = "lnRoM",
                   SAFE = TRUE,
                   verbose = FALSE,
                   parallelize = FALSE,
                   SAFE_boots = 1e6)
   setnames(out,
            c("yi_first", "vi_first", 
              "yi_second", "vi_second"),
            c("sim_y_plugin_1st", "sim_v_plugin_1st",
              "sim_y_plugin_2nd", "sim_v_plugin_2nd"))
   
   # Store results:
   results <- data.table(guide,
                         sim_dat,
                         true_point,
                         out)
   
   setTxtProgressBar(clust_out$progress, i)
   
   return(results)
  
  }
  stopCluster(clust_out$cluster)
  
  res <- rbindlist(res)  
}


```

Load the final simulation (with 1e5 iterations) for lnRoM here:

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

res <- readRDS("../../large_data/simulation_summaries/lnRoM.Rds")

head(res, 3)

```

## Calculate bias

To interpret the simulation results, it is essential to understand the difference between *estimands*, *estimators*, and *estimates*.

**Estimands** are the 'true' value.

**Estimators** are the methods used to estimate the estimand. What a tongue twister! In our case, the estimators are the 1st order effect size (e.g., definition formula), the 2nd order effect size that has been adjusted (usually using the delta method, except for Hedges' g) to reduce bias, and the SAFE method.

**Estimates** are the estimates of the estimands produced by the estimators. 

### Effect size (point estimate) bias

In the case of our effect sizes, there are two estimands that we're interested in estimating: the 'true' effect size (based on the definition formula of the effect size type) and sampling variance. To calculate the bias of our various estimators in estimating effect sizes, we calculate the mean of the estimates from each simulated dataset and subtract the estimand value (the true effect size off the 'true' values).

Here we will calculate bias in our estimates of effect sizes:

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"


bias <- function(estimates, estimand){
  return(mean(estimates) - unique(estimand))
}

point.bias <- res[, .(plugin_1st_bias = bias(sim_y_plugin_1st, true_y_plugin_1st),
                      plugin_2nd_bias = bias(sim_y_plugin_2nd, true_y_plugin_1st),
                      safe_bias = bias(yi_safe, true_y_plugin_1st)),
                  by = .(scenario_id, sample_size1, sample_size2)] |> unique()
head(point.bias)

# Melt this to make it plottable:
point.bias.long <- melt(point.bias,
                        id.vars = c("scenario_id", "sample_size1", "sample_size2"))

head(point.bias.long)

# Sort by sample size 
setorder(point.bias.long, sample_size1)

ggplot(data = point.bias.long[sample_size1 == sample_size2, ],
       aes(x = sample_size1, y = value, color = variable))+
  geom_hline(yintercept = 0)+
  geom_path(linewidth = 1)+
  xlab("Sample size")+
  ylab("Bias")+
  coord_cartesian(ylim = c(-0.01, 0.01))+
  scale_color_discrete("Estimator",
                       labels = c("plugin_1st_bias" = "1st order plugin (definition formula)",
                                  "plugin_2nd_bias" = "2nd order plugin (bias-corrected formula)",
                                  "safe_bias" = "SAFE bootstrapping"))+
  theme_bw()+
  theme(panel.border = element_blank(),
        panel.grid = element_blank(),
        legend.position = "inside",
        legend.position.inside = c(.75, .25))

```

This indicates that the least biased estimator is the first order definition formula. SAFE bootstrapping and the 2nd order plugin perform similarly.

### Sampling variance bias

Interestingly, there is no way to know the 'true' estimand for sampling variance. **WHICH I DON'T FULLY UNDERSTAND**. To calculate bias for our sampling variance estimates, we actually calculate the variance in point estimates for each estimator and use each of these as the estimand. With 3 estimators, we'll thus end up with 9 calculations of bias.

Since we're interested in relative bias (**Not entirely sure why**), we'll calculate bias as above but divide by the estimand and multiply by 100.

```{r}
#| eval: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

# First, calculate variance in point estimates as our 'estimand'
res[, var_estimand_1st := var(sim_y_plugin_1st), 
    by = .(scenario_id)]
res[, var_estimand_2nd := var(sim_y_plugin_2nd), 
    by = .(scenario_id)]
res[, var_estimand_SAFE := var(yi_safe), 
    by = .(scenario_id)]

# To make this easier to read, we'll encapsulate the relative bias in a function:
relative_bias <- function(estimates,
                          estimand){
  return(((mean(estimates) - unique(estimand)) / estimand) * 100)
}

# Now summarize and calculate relative bias per scenario ID
var.bias <- res[, .(SAFE_estimate.1st_estimand = relative_bias(vi_safe, var_estimand_1st),
                    SAFE_estimate.2nd_estimand = relative_bias(vi_safe, var_estimand_2nd),
                    SAFE_estimate.SAFE_estimand = relative_bias(vi_safe, var_estimand_SAFE),
                    plugin_1st_estimate.1st_estimand = relative_bias(sim_v_plugin_1st, var_estimand_1st),
                    plugin_1st_estimate.2nd_estimand = relative_bias(sim_v_plugin_1st, var_estimand_2nd),
                    plugin_1st_estimate.SAFE_estimand = relative_bias(sim_v_plugin_1st, var_estimand_SAFE),
                    plugin_2nd_estimate.1st_estimand = relative_bias(sim_v_plugin_2nd, var_estimand_1st),
                    plugin_2nd_estimate.2nd_estimand = relative_bias(sim_v_plugin_2nd, var_estimand_2nd),
                    plugin_2nd_estimate.SAFE_estimand = relative_bias(sim_v_plugin_2nd, var_estimand_SAFE)),
    by = .(scenario_id, sample_size1, sample_size2)] |> unique()


# Now melt:
var.bias.long <- melt(var.bias,
                      id.vars = c("scenario_id", "sample_size1", "sample_size2"))
head(var.bias.long)

# Split the 'variable' into estimator and estimand for plotting
var.bias.long[, c("Estimator", "Estimand") := tstrsplit(variable, ".", fixed = TRUE)]

# Sort the dataset by sample size
setorder(var.bias.long, sample_size1)

# Plot
ggplot(data = var.bias.long[sample_size1 == sample_size2, ], 
       aes(x = sample_size1, y = value, color = Estimator))+
    geom_path(linewidth = 1)+
  geom_hline(yintercept = 0)+
  xlab("Sample size")+
  ylab("Relative bias (%)")+
  scale_color_discrete("Estimator",
                       labels = c("plugin_1st_estimate" = "1st order plugin (definition formula)",
                                  "plugin_2nd_estimate" = "2nd order plugin (bias-corrected formula)",
                                  "SAFE_estimate" = "SAFE bootstrapping"))+
  facet_wrap(~Estimand,
             ncol = 1,
             labeller = as_labeller(c("1st_estimand" = "1st order plugin estimand\n(definition formula)",
                                    "2nd_estimand" = "2nd order plugin estimand",
                                    "SAFE_estimand" = "SAFE estimand")))+
  theme_bw()+
  theme(panel.border = element_blank(),
        panel.grid = element_blank(),
        strip.background = element_blank(),
        legend.position = "inside",
        legend.position.inside = c(.8, .9))

```

We see here that SAFE is slightly more biased than the other estimators.

## Plot all simulations results

Now let's look at the rest of the simulation results. The summaries are saved as an .Rds in the 'builds' folder in the repo.

```{r}
#| echo: true
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"


sim_results <- readRDS("builds/all_scenarios_summarized.Rds")

```

### Reciprocal

1 / x

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

var_lab <- "Relative bias of\nvariance estimates (%)"
point_lab <- "Bias of point\nestimates"

theme_SAFE <- theme_bw()+
  theme(panel.border = element_blank(),
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5),
        panel.grid = element_blank(),
        strip.background = element_blank())

pal = c("plugin_1st" = "#A8DADC",
           "plugin_2nd" = "#1D3557",
           "safe" = "#E63946")

labs = c("plugin_1st" = "1st order plugin",
           "plugin_2nd" = "2nd order plugin",
           "safe" = "SAFE")

facet_labs <- as_labeller(c("plugin_1st_mc" = "Monte Carlo 1st order plugin estimand",
                            "plugin_2nd_mc" = "Monte Carlo 2nd order plugin estimand",
                            "safe_mc" = "Monte Carlo SAFE variance estimand",
                            "true_1st" = "True 1st order point estimand",
                            "true_2nd" = "True 2nd order point estimand"))


sub_dat <- sim_results[effect_type == "reciprocal", ]
# sub_dat
setorder(sub_dat, sample_size)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias"), ], 
            aes(x = sample_size, y = value, color = estimator,
                group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("Reciprocal (1 / x)")+
  theme_SAFE+
  theme(legend.position = "none") #, legend.position.inside = c(.85, .85)
# p.point

p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias"), ], 
             aes(x = sample_size, y = value, color = estimator,
                 group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             scales = "free_y",
             labeller = facet_labs,
             nrow = 2)+
  theme_SAFE+
  theme(legend.position = "bottom")
# p.variance

p.point + p.variance + plot_layout(ncol = 1, heights = c(1/3, 2/3))

```

### SMD 4-multivariate normal

The SAFE estimator for this effect size was calculated with a multivariate normal distribution for both mean and SD.

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "SMD_normal", ]

setorder(sub_dat, sample_size1)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias") & sample_size_ratio == 1, ], 
                  aes(x = sample_size1, y = value, color = estimator,
                      group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("SMD (x1 - x2) / pooled SD",
          subtitle = "with n1==n2")+
  theme_SAFE+
  theme(legend.position = "none") 

#
p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias") & sample_size_ratio == 1, ], 
                     aes(x = sample_size1, y = value, color = estimator,
                         group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = c(plugin_1st = "Cohen's d", 
                                plugin_2nd = "Hedges' g", 
                                safe = "SAFE"))+
  facet_wrap(~estimand, 
             scales = "free_y",
             ncol = 1,
             labeller = as_labeller(c("plugin_1st_mc" = "Monte Carlo Cohen's d estimand",
                                      "plugin_2nd_mc" = "Monte Carlo Hedges' g estimand",
                                      "safe_mc" = "Monte Carlo SAFE variance estimand",
                                      "true_1st" = "True Cohen's d point estimand",
                                      "true_2nd" = "True Hedges' g point estimand")))+
  theme_SAFE+
  theme(legend.position = "bottom")

p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```

### SMD 2-multivariate normal and 2-Wishart 
With this estimator, the SAFE calculation used the normal distribution for the two means but the Wishart distribution to estimate the SD.

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "SMD_Wishart", ]
setorder(sub_dat, sample_size1)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias") & sample_size_ratio == 1, ], 
                  aes(x = sample_size1, y = value, color = estimator,
                      group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("SMD (x1 - x2) / pooled SD",
          subtitle = "with n1==n2")+
  theme_SAFE+
  theme(legend.position = "none") 

#
p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias") & sample_size_ratio == 1, ], 
                     aes(x = sample_size1, y = value, color = estimator,
                         group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = c(plugin_1st = "Cohen's d", 
                                plugin_2nd = "Hedges' g", 
                                safe = "SAFE"))+
  facet_wrap(~estimand, 
             scales = "free_y",
             ncol = 1,
             labeller = as_labeller(c("plugin_1st_mc" = "Monte Carlo Cohen's d estimand",
                                      "plugin_2nd_mc" = "Monte Carlo Hedges' g estimand",
                                      "safe_mc" = "Monte Carlo SAFE variance estimand",
                                      "true_1st" = "True Cohen's d point estimand",
                                      "true_2nd" = "True Hedges' g point estimand")))+
  theme_SAFE+
  theme(legend.position = "bottom")

p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```

### lnCVR 4-multivariate normal

The SAFE estimator for this effect size was calculated with a multivariate normal distribution for both mean and SD.

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnCVR_normal", ]
setorder(sub_dat, sample_size1)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias") & 
                                   sample_size_ratio == 1, ], 
                  aes(x = sample_size1, y = value, color = estimator,
                      group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("lnCVR",
          subtitle = "with n1==n2")+
  theme_SAFE+
  theme(legend.position = "none") 

#
p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias") & sample_size_ratio == 1, ], 
                     aes(x = sample_size1, y = value, color = estimator,
                         group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             scales = "free_y",
             ncol = 1,
             labeller = facet_labs)+
  theme_SAFE+
  theme(legend.position = "bottom")

p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```

### lnCVR 2-multivariate normal and 2-Wishart

The SAFE estimator for this effect size was calculated with a multivariate normal distribution for both mean and SD.

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnCVR_Wishart", ]
setorder(sub_dat, sample_size1)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias") & 
                                   sample_size_ratio == 1, ], 
                  aes(x = sample_size1, y = value, color = estimator,
                      group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  coord_cartesian(ylim = c(-0.05, 0.05))+
  facet_wrap(~estimand, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("lnCVR",
          subtitle = "with n1==n2")+
  theme_SAFE+
  theme(legend.position = "none") #, legend.position.inside = c(.85, .85)

#
p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias") & sample_size_ratio == 1, ], 
                     aes(x = sample_size1, y = value, color = estimator,
                         group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             scales = "free_y",
             ncol = 1,
             labeller = facet_labs)+
  theme_SAFE+
  theme(legend.position = "bottom")

p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```

### lnOR Binomial

In this effect size estimation, the SAFE calculation used a binomial distribution to draw random binomial samples for 'a' and 'c'.

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnOR", ]
setorder(sub_dat, sample_size1)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias") & n1 == n2 &
                                   true_p_a == .1 & true_p_c == .7, ], 
                  aes(x = n1, y = value, color = estimator,
                      group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  ggtitle("lnOR",
          subtitle = "with n1==n2")+
  theme_SAFE+
  theme(legend.position = "none") 

#
p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias") & n1 == n2 &
                                      true_p_a == .1 & true_p_c == .7, ], 
                     aes(x = n1, y = value, color = estimator,
                         group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             scales = "free_y",
             ncol = 1,
             labeller = facet_labs)+
  theme_SAFE+
  theme(legend.position = "bottom")

p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```

### lnOR Normal

In this effect size estimation, the SAFE calculation used a normal distribution to draw 'p1' and 'p2' from which 'a' and 'c' were calculated. **Something is still off...**

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnOR_normal", ]
setorder(sub_dat, sample_size1)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias") & n1 == n2 &
                                   true_p_a == .1 & true_p_c == .7, ], 
                  aes(x = n1, y = value, color = estimator,
                      group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             scales = "free_y",
             labeller = facet_labs)+
  coord_cartesian(ylim = c(-2, 2))+
  ggtitle("lnOR",
          subtitle = "with n1==n2")+
  theme_SAFE+
  theme(legend.position = "none") 

#
p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias") & n1 == n2 &
                                      true_p_a == .1 & true_p_c == .7, ], 
                     aes(x = n1, y = value, color = estimator,
                         group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             scales = "free_y",
             ncol = 1,
             labeller = facet_labs)+
  theme_SAFE+
  theme(legend.position = "bottom")

p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```

### lnRR Binomial

In this effect size estimation, the SAFE calculation drew 'a' and 'c' from a binomial distribution.

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnRR", ]
setorder(sub_dat, sample_size1)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias") & n1 == n2 &
                                   true_p_a == .1 & true_p_c == .7, ], 
                  aes(x = n1, y = value, color = estimator,
                      group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             scales = "free_y",
             labeller = facet_labs)+
  coord_cartesian(ylim = c(-2, 2))+
  ggtitle("lnRR",
          subtitle = "with n1==n2")+
  theme_SAFE+
  theme(legend.position = "none") 

#
p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias") & n1 == n2 &
                                      true_p_a == .1 & true_p_c == .7, ], 
                     aes(x = n1, y = value, color = estimator,
                         group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             scales = "free_y",
             ncol = 1,
             labeller = facet_labs)+
  theme_SAFE+
  theme(legend.position = "bottom")

p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```

### lnRR Normal

In this effect size estimation, the SAFE calculation drew 'p1' and 'p2' from a normal distribution.

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnRR_normal", ]
setorder(sub_dat, sample_size1)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias") & n1 == n2 &
                                   true_p_a == .1 & true_p_c == .7, ], 
                  aes(x = n1, y = value, color = estimator,
                      group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("lnRR",
          subtitle = "with n1==n2")+
  theme_SAFE+
  theme(legend.position = "none") 

#
p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias") & n1 == n2 &
                                      true_p_a == .1 & true_p_c == .7, ], 
                     aes(x = n1, y = value, color = estimator,
                         group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             scales = "free_y",
             ncol = 1,
             labeller = facet_labs)+
  theme_SAFE+
  theme(legend.position = "bottom")

p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```

### Hardy Weinberg Disequilibrium

In this effect size estimation, the SAFE calculation drew 'n_AA', 'n_Aa', and 'n_aa' from a binomial distribution.

```{r}
#| echo: false
#| attr-source: "style='font-size: 0.8em;'"
#| attr-output: "style='font-size: 0.7em'"

sub_dat <- sim_results[effect_type == "lnHWE_A", ]
setorder(sub_dat, sample_size1)

p.point <- ggplot(data = sub_dat[calculation %in% c("bias") & #n1 == n2 &
                                   p_AA == 0.25 & p_aa == 0.25 & p_Aa == 0.5, ], 
                  aes(x = n, y = value, color = estimator,
                      group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  ylab(point_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             scales = "free_y",
             labeller = facet_labs)+
  ggtitle("lnHWD")+
  theme_SAFE+
  theme(legend.position = "none") 

#
p.variance <- ggplot(data = sub_dat[calculation %in% c("relative_bias") & 
                                   p_AA == 0.25 & p_aa == 0.25 & p_Aa == 0.5, ], 
                     aes(x = n, y = value, color = estimator,
                         group = estimator))+
  geom_hline(yintercept = 0)+
  geom_path(lwd = 1)+
  ylab(var_lab)+
  xlab("Sample size")+
  scale_color_manual(name = "Estimator", 
                     values = pal,
                     labels = labs)+
  facet_wrap(~estimand, 
             scales = "free_y",
             ncol = 1,
             labeller = facet_labs)+
  theme_SAFE+
  theme(legend.position = "bottom")


p.point + xlab(NULL) + p.variance + plot_layout(ncol = 1, heights = c(1/4, 3/4))

```
